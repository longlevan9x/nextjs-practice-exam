[
  {
    "id": 1,
    "question": "<p>A Developer is creating a serverless application that will process sensitive data. The AWS Lambda function must encrypt all data that is written to /tmp storage at rest.</p><p>How should the Developer encrypt this data?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Configure Lambda to use an AWS KMS <em>customer managed</em> customer master key (CMK). Use the CMK to generate a data key and encrypt all data prior to writing to /tmp storage.</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Enable default encryption on an Amazon S3 bucket using an AWS KMS <em>customer managed</em> customer master key (CMK). Mount the S3 bucket to /tmp.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Attach the Lambda function to a VPC and encrypt Amazon EBS volumes at rest using the AWS managed CMK. Mount the EBS volume to /tmp.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Enable secure connections over HTTPS for the AWS Lambda API endpoints using Transport Layer Security (TLS).</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>On a per-function basis, you can configure Lambda to use an encryption key that you create and manage in AWS Key Management Service. These are referred to as <em>customer managed</em> customer master keys (CMKs) or customer managed keys. If you don't configure a customer managed key, Lambda uses an AWS managed CMK named aws/lambda, which Lambda creates in your account.</p><p>The CMK can be used to generate a data encryption key that can be used for encrypting all data uploaded to Lambda or generated by Lambda.</p><p><strong>CORRECT: </strong>\"Configure Lambda to use an AWS KMS <em>customer managed</em> customer master key (CMK). Use the CMK to generate a data key and encrypt all data prior to writing to /tmp storage\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Attach the Lambda function to a VPC and encrypt Amazon EBS volumes at rest using the AWS managed CMK. Mount the EBS volume to /tmp\" is incorrect. You cannot attach an EBS volume to a Lambda function.</p><p><strong>INCORRECT:</strong> \"Enable default encryption on an Amazon S3 bucket using an AWS KMS <em>customer managed</em> customer master key (CMK). Mount the S3 bucket to /tmp\" is incorrect. You cannot mount an S3 bucket to a Lambda function.</p><p><strong>INCORRECT:</strong> \"Enable secure connections over HTTPS for the AWS Lambda API endpoints using Transport Layer Security (TLS)\" is incorrect. The Lambda API endpoints are always encrypted using TLS and this is encryption in-transit not encryption at-rest.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/security-dataprotection.html\">https://docs.aws.amazon.com/lambda/latest/dg/security-dataprotection.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-lambda/\">https://digitalcloud.training/aws-lambda/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/lambda/latest/dg/security-dataprotection.html",
      "https://digitalcloud.training/aws-lambda/"
    ]
  },
  {
    "id": 2,
    "question": "<p>A developer is implementing Amazon ElastiCache in an application that needs to reflect real-time data on dashboards. The data is sourced from a database and needs to be stored in the cache.</p><p>What would be the ideal caching mechanism for this requirement?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>A write-behind cache</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>A write-through cache</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>A lazy-loading cache</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>A read-through cache</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Database",
    "explanation": "<p>The write-through caching strategy ensures that data is written into the cache every time it's updated in the database. This makes it an ideal strategy for scenarios where real-time data is required on dashboards as it reduces the chances of a cache miss, and any read request will have the latest data.</p><p><strong>CORRECT: </strong>\"A write-through cache\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"A lazy-loading cache\" is incorrect.</p><p>Lazy-loading strategy only caches the data when a request for that data is made. This might cause a delay in populating real-time dashboards during the first request for data.</p><p><strong>INCORRECT:</strong> \"A write-behind cache\" is incorrect.</p><p>Write-behind caching is not supported by Amazon ElastiCache. This strategy can lead to data inconsistency between the cache and the database.</p><p><strong>INCORRECT:</strong> \"A read-through cache\" is incorrect.</p><p>Read-through caches are not supported by Amazon ElastiCache.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Strategies.html\">https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Strategies.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-elasticache/\">https://digitalcloud.training/amazon-elasticache/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Strategies.html",
      "https://digitalcloud.training/amazon-elasticache/"
    ]
  },
  {
    "id": 3,
    "question": "<p>A junior developer has been assigned the project of making updates to a current application using AWS Cloud Development Kit (CDK).</p><p>How can the developer revert to a previous version if there is an error?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Once CloudFormation has been installed, it can be used to revert to previous versions.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Only make changes in the deployment phase, and never during synthesis.</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Once CloudFormation has been installed, it can be used to track changes in application stacks.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Once CloudFormation has been added to the application, it can be used to manage the scope.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Developer Tools",
    "explanation": "<p>Synthesis is the process of converting AWS CDK stacks to AWS CloudFormation templates and assets. Changes should only be during the deployment phase and after AWS CloudFormation template has been created. This will allow it to roll back the change if there are any problems.</p><p><strong>CORRECT:</strong> \"Only make changes in the deployment phase, and never during synthesis\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Once CloudFormation has been installed, it can be used to revert to previous versions\" is incorrect. The CDK Toolkit already provides the ability to convert CDK stacks into CloudFormation templates. There is no need to install CloudFormation.</p><p><strong>INCORRECT:</strong> \"Once CloudFormation has been added to the application, it can be used to manage the scope\" is incorrect. The CDK Toolkit already provides the ability to convert CDK stacks into CloudFormation templates. It is not used to manage the scope.</p><p><strong>INCORRECT:</strong> \"Once synthesis is complete, it can be used to track drift changes\" is incorrect. CloudFormation can detect drift changes if changes are made outside of CloudFormation management. Synthesis is the process of converting AWS CDK stacks to AWS CloudFormation templates.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/cdk/v2/guide/best-practices.html\">https://docs.aws.amazon.com/cdk/v2/guide/best-practices.html</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/cdk/v2/guide/best-practices.html"
    ]
  },
  {
    "id": 4,
    "question": "<p>A programmer is rolling out a new solution to Amazon ECS. This solution necessitates secure handling and access to diverse variables such as credentials, remote API authentication details, and the API URL. The remote API authentication information and API URL should be accessible across all versions of the solution, spanning development, testing, and production environments.</p><p>What is the most efficient method for the programmer to access these variables with minimal modifications to the solution?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Utilize AWS Secrets Manager to store these variables and retrieve them directly within the application using AWS SDK.</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Use AWS S3 to store these variables and access them via AWS SDK within the application.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Include these variables directly in the application code and use version control system to manage different versions.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Create environment variables for these details and access them within the application code.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>AWS Secrets Manager is designed to handle sensitive data like this. It enables you to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. Using AWS Secrets Manager, you can secure and manage secrets used to access resources in the AWS Cloud, on third-party services, and on-premises.</p><p><strong>CORRECT: </strong>\"Utilize AWS Secrets Manager to store these variables and retrieve them directly within the application using AWS SDK\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Include these variables directly in the application code and use version control system to manage different versions\" is incorrect.</p><p>Including sensitive data directly in the application code is not a secure practice and doesn't comply with the principle of least privilege or best security practices.</p><p><strong>INCORRECT:</strong> \"Create environment variables for these details and access them within the application code\" is incorrect.</p><p>Although environment variables can be used to pass some configuration to the application, they're typically visible in plaintext in multiple places such as ECS Task Definitions or the ECS console. This makes them unsuitable for sensitive data like credentials or API keys.</p><p><strong>INCORRECT:</strong> \"Use AWS S3 to store these variables and access them via AWS SDK within the application\" is incorrect.</p><p>AWS S3 is primarily a storage service and using it to store and manage secrets doesn't align with security best practices.</p><p><strong>References:</strong></p><p><a href=\"https://aws.amazon.com/secrets-manager/\">https://aws.amazon.com/secrets-manager/</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-secrets-manager/\">https://digitalcloud.training/aws-secrets-manager/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://aws.amazon.com/secrets-manager/",
      "https://digitalcloud.training/aws-secrets-manager/"
    ]
  },
  {
    "id": 5,
    "question": "<p>A Developer is creating a REST service using Amazon API Gateway with AWS Lambda integration. The service adds data to a spreadsheet and the data is sent as query string parameters in the method request.</p><p>How should the Developer convert the query string parameters to arguments for the Lambda function?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Change the integration type</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Include the Amazon Resource Name (ARN) of the Lambda function</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Create a mapping template</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Enable request validation</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>Standard API Gateway <a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/models-mappings.html\">parameter and response code mapping templates</a> allow you to map parameters one-to-one and map a family of integration response status codes (matched by a regular expression) to a single response status code.</p><p>Mapping template overrides provides you with the flexibility to perform many-to-one parameter mappings; override parameters after standard API Gateway mappings have been applied; conditionally map parameters based on body content or other parameter values; programmatically create new parameters on the fly; and override status codes returned by your integration endpoint.</p><p>Any type of request parameter, response header, or response status code may be overridden.</p><p>Following are example uses for a mapping template override:</p><p>To create a new header (or overwrite an existing header) as a concatenation of two parameters</p><p>To override the response code to a success or failure code based on the contents of the body</p><p>To conditionally remap a parameter based on its contents or the contents of some other parameter</p><p>To iterate over the contents of a json body and remap key value pairs to headers or query strings</p><p>Therefore, the Developer can convert the query string parameters by creating a mapping template.</p><p><strong>CORRECT: </strong>\"Create a mapping template\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Enable request validation\" is incorrect as this is used to configure API Gateway to perform basic validation of an API request before proceeding with the integration request.</p><p><strong>INCORRECT:</strong> \"Include the Amazon Resource Name (ARN) of the Lambda function\" is incorrect as that doesn’t assist with converting the query string parameters.</p><p><strong>INCORRECT:</strong> \"Change the integration type\" is incorrect as to perform a conversion the Lambda integration does not need to have a different integration type such as Lambda proxy.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-override-request-response-parameters.html\">https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-override-request-response-parameters.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-api-gateway/\">https://digitalcloud.training/amazon-api-gateway/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/apigateway/latest/developerguide/models-mappings.html",
      "https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-override-request-response-parameters.html",
      "https://digitalcloud.training/amazon-api-gateway/"
    ]
  },
  {
    "id": 6,
    "question": "<p>An application will be hosted on the AWS Cloud. Developers will be using an Agile software development methodology with regular updates deployed through a continuous integration and delivery (CI/CD) model. Which AWS service can assist the Developers with automating the build, test, and deploy phases of the release process every time there is a code change?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>AWS CloudFormation</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>AWS CodeBuild</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>AWS CodePipeline</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>AWS Elastic Beanstalk</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Developer Tools",
    "explanation": "<p>AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps required to release your software. You can quickly model and configure the different stages of a software release process. CodePipeline automates the steps required to release your software changes continuously.</p><p>Specifically, you can:</p><p><strong>Automate your release processes</strong>: CodePipeline fully automates your release process from end to end, starting from your source repository through build, test, and deployment. You can prevent changes from moving through a pipeline by including a manual approval action in any stage except a Source stage. You can release when you want, in the way you want, on the systems of your choice, across one instance or multiple instances.</p><p><strong>Establish a consistent release process</strong>: Define a consistent set of steps for every code change. CodePipeline runs each stage of your release according to your criteria.</p><p><strong>Speed up delivery while improving quality</strong>: You can automate your release process to allow your developers to test and release code incrementally and speed up the release of new features to your customers.</p><p><strong>Use your favorite tools</strong>: You can incorporate your existing source, build, and deployment tools into your pipeline.</p><p><strong>View progress at a glance</strong>: You can review real-time status of your pipelines, check the details of any alerts, retry failed actions, view details about the source revisions used in the latest pipeline execution in each stage, and manually rerun any pipeline.</p><p><strong>View pipeline history details</strong>: You can view details about executions of a pipeline, including start and end times, run duration, and execution IDs.</p><p>Therefore, AWS CodePipeline is the perfect tool for the Developer’s requirements.</p><p><strong>CORRECT: </strong>\"AWS CodePipeline\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"AWS CloudFormation\" is incorrect as CloudFormation is not triggered by changes in a source code repository. You must create change sets for deploying updates.</p><p><strong>INCORRECT:</strong> \"AWS Elastic Beanstalk\" is incorrect as this is a platform service that can be used to deploy code to managed runtimes such as Nodejs. It does not update automatically based on changes to source code. You must update that environment when you need to release new code.</p><p><strong>INCORRECT:</strong> \"AWS CodeBuild\" is incorrect as CodeBuild is used for compiling code, running unit tests and creating the deployment package. It does not manage the deployment of the code.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/codepipeline/latest/userguide/welcome-what-can-I-do.html\">https://docs.aws.amazon.com/codepipeline/latest/userguide/welcome-what-can-I-do.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-developer-tools/\">https://digitalcloud.training/aws-developer-tools/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/codepipeline/latest/userguide/welcome-what-can-I-do.html",
      "https://digitalcloud.training/aws-developer-tools/"
    ]
  },
  {
    "id": 7,
    "question": "<p>A static website that serves a collection of images runs from an Amazon S3 bucket in the us-east-1 region. The website is gaining in popularity and is now being viewed around the world. How can a Developer improve the performance of the website for global users?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use Amazon S3 Transfer Acceleration to improve the performance of the website</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Use cross region replication to replicate the bucket to several global regions</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use Amazon CloudFront to cache the website content</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Use Amazon ElastiCache to cache the website content</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>CloudFront is a web service that gives businesses and web application developers an easy and cost-effective way to distribute content with low latency and high data transfer speeds. CloudFront is a good choice for distribution of frequently accessed static content that benefits from edge delivery—like popular website images, videos, media files or software downloads.</p><p><strong>CORRECT: </strong>\"Use Amazon CloudFront to cache the website content\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Use Amazon ElastiCache to cache the website content\" is incorrect as ElastiCache is used for caching the contents of databases, not S3 buckets.</p><p><strong>INCORRECT:</strong> \"Use cross region replication to replicate the bucket to several global regions\" is incorrect as though this would get the content closer to users it would not provide a mechanism for connecting to those copies. This could be achieved using Route 53 latency based routing however it would be easier to use CloudFront.</p><p><strong>INCORRECT:</strong> \"Use Amazon S3 Transfer Acceleration to improve the performance of the website\" is incorrect as this service is used for improving the performance of uploads to Amazon S3.</p><p><strong>References:</strong></p><p><a href=\"https://aws.amazon.com/blogs/networking-and-content-delivery/amazon-s3-amazon-cloudfront-a-match-made-in-the-cloud/\">https://aws.amazon.com/blogs/networking-and-content-delivery/amazon-s3-amazon-cloudfront-a-match-made-in-the-cloud/</a></p><p><a href=\"https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-serve-static-website/\">https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-serve-static-website/</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-cloudfront/\">https://digitalcloud.training/amazon-cloudfront/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://aws.amazon.com/blogs/networking-and-content-delivery/amazon-s3-amazon-cloudfront-a-match-made-in-the-cloud/",
      "https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-serve-static-website/",
      "https://digitalcloud.training/amazon-cloudfront/"
    ]
  },
  {
    "id": 8,
    "question": "<p>A new application will be hosted on the domain name dctlabs.com using an Amazon API Gateway REST API front end. The Developer needs to configure the API with a path to dctlabs.com/products that will be accessed using the HTTP GET verb. How MUST the Developer configure the API? (Select TWO</p>",
    "corrects": [
      3,
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Create a GET resource</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Create a /products method</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Create a /products resource</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Create a GET method</p>",
        "correct": true
      },
      {
        "id": 5,
        "answer": "<p>Create a /GET method</p>",
        "correct": false
      }
    ],
    "multiple": true,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>An API Gateway REST API is a collection of HTTP resources and methods that are integrated with backend HTTP endpoints, Lambda functions, or other AWS services. You can deploy this collection in one or more stages. Typically, API resources are organized in a resource tree according to the application logic. Each API resource can expose one or more API methods that have unique HTTP verbs supported by API Gateway.</p><p><img src=\"https://img-c.udemycdn.com/redactor/raw/2020-04-21_06-14-47-f88043be97e72b975a068fc68a6df375.png\" style=\"display: none;\"><span class=\"ud-component--base-components--open-full-size-image\"></span></p><div class=\"open-full-size-image--wrapper--R4gIm\" data-purpose=\"open-full-size-image\"><img src=\"https://img-c.udemycdn.com/redactor/raw/2020-04-21_06-14-47-f88043be97e72b975a068fc68a6df375.png\" alt=\"\" loading=\"eager\"><button type=\"button\" class=\"ud-btn ud-btn-medium ud-btn-link ud-heading-sm open-full-size-image--backdrop--Zor3j\"><svg aria-label=\"Larger image\" role=\"img\" focusable=\"false\" class=\"ud-icon ud-icon-large ud-icon-color-neutral\"><use xlink:href=\"#icon-search\"></use></svg></button></div><p></p><p>As you can see from the image above, the Developer would need to create a resource which in this case would be /products. The Developer would then create a GET method within the resource.</p><p><strong>CORRECT: </strong>\"Create a /products resource\" is a correct answer.</p><p><strong>CORRECT: </strong>\"Create a GET method\" is a correct answer.</p><p><strong>INCORRECT:</strong> \"Create a /products method\" is incorrect as a resource should be created.</p><p><strong>INCORRECT:</strong> \"Create a GET resource\" is incorrect as a method should be created.</p><p><strong>INCORRECT:</strong> \"Create a /GET method\" is incorrect as a method is not preceded by a slash.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-basic-concept.html\">https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-basic-concept.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-api-gateway/\">https://digitalcloud.training/amazon-api-gateway/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-basic-concept.html",
      "https://digitalcloud.training/amazon-api-gateway/"
    ]
  },
  {
    "id": 9,
    "question": "<p>An engineer is using a Border Gateway Protocol (BGP) enabled AWS VPN connection to establish communication between on-site servers and Amazon EC2 instances in their account. The engineer is successful in accessing an EC2 instance in Subnet-X but is facing issues when attempting to reach an EC2 instance in Subnet-Y within the same VPC.</p><p>Which logging mechanism can the engineer employ to confirm if the traffic is getting to Subnet-Y?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Check Amazon CloudWatch Logs for the EC2 instance in Subnet-Y. CloudWatch Logs for EC2 instances primarily provide information about instance status and operations, not about network traffic.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Use AWS CloudTrail logs to verify traffic to Subnet-Y. CloudTrail primarily logs API calls in AWS and not the traffic flow at the network interface level.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use VPC Flow Logs to check the inbound and outbound traffic of Subnet-Y.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Consult AWS Config logs to trace the traffic. AWS Config tracks changes in resource configurations and doesn't provide insight into traffic flow.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>In this scenario, AWS VPC Flow Logs would provide the required visibility. These logs capture information about the IP traffic going to and from network interfaces in the VPC. Therefore, it's the appropriate tool to verify if the traffic is reaching Subnet-Y.</p><p><strong>CORRECT: </strong>\"Use VPC Flow Logs to check the inbound and outbound traffic of Subnet-Y\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Check Amazon CloudWatch Logs for the EC2 instance in Subnet-Y\" is incorrect.</p><p>CloudWatch Logs for EC2 instances primarily provide information about instance status and operations, not about network traffic</p><p><strong>INCORRECT:</strong> \"Use AWS CloudTrail logs to verify traffic to Subnet-Y\" is incorrect.</p><p>CloudTrail primarily logs API calls in AWS and not the traffic flow at the network interface level</p><p><strong>INCORRECT:</strong> \"Consult AWS Config logs to trace the traffic\" is incorrect.</p><p>AWS Config tracks changes in resource configurations and doesn't provide insight into traffic flow.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html\">https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-vpc/\">https://digitalcloud.training/amazon-vpc/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html",
      "https://digitalcloud.training/amazon-vpc/"
    ]
  },
  {
    "id": 10,
    "question": "<p>There are multiple AWS accounts across multiple regions managed by a company. The operations team require a single operational dashboard that displays some key performance metrics from these accounts and regions. What is the SIMPLEST solution?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Create an Amazon CloudWatch cross-account cross-region dashboard</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Create an Amazon CloudWatch dashboard in one account and region and import the data from the other accounts and regions</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Create an AWS Lambda function that collects metrics from each account and region and pushes the metrics to the account where the dashboard has been created</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Create an Amazon CloudTrail trail that applies to all regions and deliver the logs to a single Amazon S3 bucket. Create a dashboard using the data in the bucket</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Management & Governance",
    "explanation": "<p>You can create <em>cross-account cross-Region dashboards</em>, which summarize your CloudWatch data from multiple AWS accounts and multiple Regions into one dashboard. From this high-level dashboard you can get a view of your entire application, and also drill down into more specific dashboards without having to log in and out of accounts or switch Regions.</p><p>You can create cross-account cross-Region dashboards in the AWS Management Console and programmatically.</p><p><strong>CORRECT: </strong>\"Create an Amazon CloudWatch cross-account cross-region dashboard\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Create an Amazon CloudWatch dashboard in one account and region and import the data from the other accounts and regions\" is incorrect as this is more complex and unnecessary.</p><p><strong>INCORRECT:</strong> \"Create an AWS Lambda function that collects metrics from each account and region and pushes the metrics to the account where the dashboard has been created\" is incorrect as this is not a simple solution.</p><p><strong>INCORRECT:</strong> \"Create an Amazon CloudTrail trail that applies to all regions and deliver the logs to a single Amazon S3 bucket. Create a dashboard using the data in the bucket\" is incorrect as CloudTrail logs API activity, not performance metrics.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_xaxr_dashboard.html\">https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_xaxr_dashboard.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-cloudwatch/\">https://digitalcloud.training/amazon-cloudwatch/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_xaxr_dashboard.html",
      "https://digitalcloud.training/amazon-cloudwatch/"
    ]
  },
  {
    "id": 11,
    "question": "<p>A company has deployed a REST API using Amazon API Gateway with a Lambda authorizer. The company needs to log who has accessed the API and how the caller accessed the API. They also require logs that include errors and execution traces for the Lambda authorizer.</p><p>Which combination of actions should the Developer take to meet these requirements? (Select TWO.)</p>",
    "corrects": [
      3,
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Enable detailed logging in Amazon CloudWatch.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Enable server access logging.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Enable API Gateway access logs.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Enable API Gateway execution logging.</p>",
        "correct": true
      },
      {
        "id": 5,
        "answer": "<p>Create an API Gateway usage plan.</p>",
        "correct": false
      }
    ],
    "multiple": true,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>There are two types of API logging in CloudWatch: execution logging and access logging. In execution logging, API Gateway manages the CloudWatch Logs. The process includes creating log groups and log streams, and reporting to the log streams any caller's requests and responses.</p><p>The logged data includes errors or execution traces (such as request or response parameter values or payloads), data used by Lambda authorizers, whether API keys are required, whether usage plans are enabled, and so on.</p><p>In access logging, you, as an API Developer, want to log who has accessed your API and how the caller accessed the API. You can create your own log group or choose an existing log group that could be managed by API Gateway.</p><p><strong>CORRECT: </strong>\"Enable API Gateway execution logging\" is a correct answer.</p><p><strong>CORRECT: </strong>\"Enable API Gateway access logs\" is also a correct answer.</p><p><strong>INCORRECT:</strong> \"Enable detailed logging in Amazon CloudWatch\" is incorrect. Detailed logging does not provide the requested information.</p><p><strong>INCORRECT:</strong> \"Create an API Gateway usage plan\" is incorrect. This will not enable logging.</p><p><strong>INCORRECT:</strong> \"Enable server access logging\" is incorrect. This is a type of logging that applies to Amazon S3 buckets.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-logging.html\">https://docs.aws.amazon.com/apigateway/latest/Developerguide/set-up-logging.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-cloudwatch/\">https://digitalcloud.training/amazon-cloudwatch/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-logging.html",
      "https://digitalcloud.training/amazon-cloudwatch/"
    ]
  },
  {
    "id": 12,
    "question": "<p>An organization needs to create a central file storage solution that scales on demand and can be used by multiple Amazon Elastic Compute Cloud (EC2) instances and AWS Lambda functions. Which storage solution will meet these requirements?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Create an Amazon ElastiCache cluster.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Create an Amazon EBS Multi-Attach volume.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Create an Amazon Elastic File System (EFS) file system.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Create an AWS Storage Gateway volume gateway.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Storage",
    "explanation": "<p>Amazon Elastic File System (EFS) provides a scalable storage solution that does not require provisioning. It can scale up and down based on files stored. It can be used as a file source for multiple computing services such as Amazon Elastic Compute Cloud (EC2), Amazon Elastic Container Service (ECS), AWS Lambda.</p><p><strong>CORRECT</strong>: \"Create an Amazon Elastic File System (EFS) file system\" is the correct answer (as explained above.)</p><p><strong>INCORRECT</strong>: \"Create an Amazon ElastiCache cluster\" is incorrect.</p><p>Amazon ElastiCache is a database caching service; it cannot be used for file storage.</p><p><strong>INCORRECT</strong>: \"Create an Amazon EBS Multi-Attach volume\" is incorrect.</p><p>Amazon EBS Multi-Attach Provisioned IOPS SSD can be used to attach a volume to multiple EC2 instances but not to other computing services such as Lambda.</p><p><strong>INCORRECT</strong>: \"Create an AWS Storage Gateway volume gateway\" is incorrect.</p><p>Amazon Storage Gateway is used for hybrid infrastructure set-ups that allows on-premises infrastructure to use AWS cloud storage.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/efs/latest/ug/whatisefs.html\">https://docs.aws.amazon.com/efs/latest/ug/whatisefs.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-efs/\">https://digitalcloud.training/amazon-efs/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/efs/latest/ug/whatisefs.html",
      "https://digitalcloud.training/amazon-efs/"
    ]
  },
  {
    "id": 13,
    "question": "<p>A company is developing a new online game that will run on top of Amazon ECS. Four distinct Amazon ECS services will be part of the architecture, each requiring specific permissions to various AWS services. The company wants to optimize the use of the underlying Amazon EC2 instances by bin packing the containers based on memory reservation.</p><p>Which configuration would allow the Development team to meet these requirements MOST securely</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Create four distinct IAM roles, each containing the required permissions for the associated ECS services, then configure each ECS service to reference the associated IAM role</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Create a new Identity and Access Management (IAM) instance profile containing the required permissions for the various ECS services, then associate that instance role with the underlying EC2 instances</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Create four distinct IAM roles, each containing the required permissions for the associated ECS services, then configure each ECS task definition to reference the associated IAM role</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Create four distinct IAM roles, each containing the required permissions for the associated ECS services, then, create an IAM group and configure the ECS cluster to reference that group</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>With IAM roles for Amazon ECS tasks, you can specify an IAM role that can be used by the containers in a task. Applications must sign their AWS API requests with AWS credentials, and this feature provides a strategy for managing credentials for your applications to use, similar to the way that Amazon EC2 instance profiles provide credentials to EC2 instances.</p><p><img src=\"https://img-c.udemycdn.com/redactor/raw/2020-04-21_06-21-36-8e63335980c5cab31bb81697b00df2f2.png\" style=\"display: none;\"><span class=\"ud-component--base-components--open-full-size-image\"></span></p><div class=\"open-full-size-image--wrapper--R4gIm\" data-purpose=\"open-full-size-image\"><img src=\"https://img-c.udemycdn.com/redactor/raw/2020-04-21_06-21-36-8e63335980c5cab31bb81697b00df2f2.png\" alt=\"\" loading=\"eager\"><button type=\"button\" class=\"ud-btn ud-btn-medium ud-btn-link ud-heading-sm open-full-size-image--backdrop--Zor3j\"><svg aria-label=\"Larger image\" role=\"img\" focusable=\"false\" class=\"ud-icon ud-icon-large ud-icon-color-neutral\"><use xlink:href=\"#icon-search\"></use></svg></button></div><p></p><p>Instead of creating and distributing your AWS credentials to the containers or using the EC2 instance’s role, you can associate an IAM role with an ECS task definition or RunTask API operation. The applications in the task’s containers can then use the AWS SDK or CLI to make API requests to authorized AWS services.</p><p>In this case each service requires access to different AWS services so following the principal of least privilege it is best to assign as a separate role to each task definition.</p><p><strong>CORRECT: </strong>\"Create four distinct IAM roles, each containing the required permissions for the associated ECS services, then configure each ECS task definition to reference the associated IAM role\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Create a new Identity and Access Management (IAM) instance profile containing the required permissions for the various ECS services, then associate that instance role with the underlying EC2 instances\" is incorrect. It is a best practice to use IAM roles for tasks instead of assigning the roles to the container instances.</p><p><strong>INCORRECT:</strong> \"Create four distinct IAM roles, each containing the required permissions for the associated ECS services, then configure each ECS service to reference the associated IAM role\" is incorrect as the reference should be made within the task definition.</p><p><strong>INCORRECT:</strong> \"Create four distinct IAM roles, each containing the required permissions for the associated ECS services, then, create an IAM group and configure the ECS cluster to reference that group\" is incorrect as the reference should be made within the task definition.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html\">https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-ecs-and-eks/\">https://digitalcloud.training/amazon-ecs-and-eks/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html",
      "https://digitalcloud.training/amazon-ecs-and-eks/"
    ]
  },
  {
    "id": 14,
    "question": "<p>A company operates a multimedia sharing service on AWS. The service is hosted on Amazon EC2 instances in an Auto Scaling group, serving as the target for an Application Load Balancer (ALB).</p><p>The multimedia files are stored in an Amazon S3 bucket. The company is developing a feature for system request testing, which will redirect these requests to a separate target group hosting a test version of the application.</p><p>How can this be accomplished most efficiently?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Replicate the existing application and host it on a distinct EC2 instance. Manually route test requests to this instance.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Create a separate AWS Lambda function to handle the test requests and direct them to the new target group.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use ALB content-based routing. Create a separate target group for the test version of the application and route requests identified by a specific cookie.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Create a new S3 bucket to host the test variant of the application. Redirect all test requests to this new bucket.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Compute",
    "explanation": "<p>The most efficient solution is to use the ALB's content-based routing feature with a cookie-based strategy. This way, test requests identified by a specific cookie can be directed to the new target group hosting the test variant of the application, without any significant changes to the existing setup.</p><p><strong>CORRECT: </strong>\"Use ALB content-based routing. Create a separate target group for the test version of the application and route requests identified by a specific cookie\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Replicate the existing application and host it on a distinct EC2 instance. Manually route test requests to this instance\" is incorrect.</p><p>This approach doesn't leverage the ALB's content-based routing and adds unnecessary manual work</p><p><strong>INCORRECT:</strong> \"Create a new S3 bucket to host the test variant of the application. Redirect all test requests to this new bucket\" is incorrect.</p><p>This method doesn't make use of the ALB and EC2 instances for application hosting, thus inefficient</p><p><strong>INCORRECT:</strong> \"Create a separate AWS Lambda function to handle the test requests and direct them to the new target group\" is incorrect.</p><p>This is inefficient as it adds unnecessary complexity and circumvents the routing features of the ALB</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html\">https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-elastic-load-balancing-aws-elb/\">https://digitalcloud.training/aws-elastic-load-balancing-aws-elb/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html",
      "https://digitalcloud.training/aws-elastic-load-balancing-aws-elb/"
    ]
  },
  {
    "id": 15,
    "question": "<p>An organization has an account for each environment: Production, Testing, Development. A Developer with an IAM user in the Development account needs to launch resources in the Production and Testing accounts. What is the MOST efficient way to provide access</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Create a role with the required permissions in the Production and Testing accounts and have the Developer assume that role</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Create an IAM group in the Production and Testing accounts and add the Developer’s user from the Development account to the groups</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Create a separate IAM user in each account and have the Developer login separately to each account</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Create an IAM permissions policy in the Production and Testing accounts and reference the IAM user in the Development account</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>You can grant your IAM users’ permission to switch to roles within your AWS account or to roles defined in other AWS accounts that you own. This is known as cross-account access.</p><p>In the image below a user in the Development account needs to access an S3 bucket in the Production account:</p><p><img src=\"https://img-c.udemycdn.com/redactor/raw/2020-04-21_06-08-34-c04908e5b40ad6142024fee3a875a0b2.png\" style=\"display: none;\"><span class=\"ud-component--base-components--open-full-size-image\"></span></p><div class=\"open-full-size-image--wrapper--R4gIm\" data-purpose=\"open-full-size-image\"><img src=\"https://img-c.udemycdn.com/redactor/raw/2020-04-21_06-08-34-c04908e5b40ad6142024fee3a875a0b2.png\" alt=\"\" loading=\"eager\"><button type=\"button\" class=\"ud-btn ud-btn-medium ud-btn-link ud-heading-sm open-full-size-image--backdrop--Zor3j\"><svg aria-label=\"Larger image\" role=\"img\" focusable=\"false\" class=\"ud-icon ud-icon-large ud-icon-color-neutral\"><use xlink:href=\"#icon-search\"></use></svg></button></div><p></p><p>The user is able to assume the role in the Production account and access the S3 bucket. This is more efficient than providing the user with multiple accounts. In this scenario the user requests to switch to the role through either the console or the API/CLI.</p><p><strong>CORRECT: </strong>\"Create a role with the required permissions in the Production and Testing accounts and have the Developer assume that role\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Create a separate IAM user in each account and have the Developer login separately to each account\" is incorrect as this is not the most efficient method of providing access. Cross-account access is preferred .</p><p><strong>INCORRECT:</strong> \"Create an IAM group in the Production and Testing accounts and add the Developer’s user from the Development account to the groups\" is incorrect as you cannot add an IAM user from another AWS account to a group.</p><p><strong>INCORRECT:</strong> \"Create an IAM permissions policy in the Production and Testing accounts and reference the IAM user in the Development account\" is incorrect as you cannot reference an IAM user from another AWS account in a permissions policy.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_aws-accounts.html\">https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_aws-accounts.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-iam/\">https://digitalcloud.training/aws-iam/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_aws-accounts.html",
      "https://digitalcloud.training/aws-iam/"
    ]
  },
  {
    "id": 16,
    "question": "<p>A company has a production application deployed using AWS Elastic Beanstalk. A new version of the application must be installed, and the company cannot tolerate any website downtime. If the application update fails, rollback should be fast and easy.</p><p>What deployment method should be used?</p>",
    "corrects": [
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>All at once</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Rolling</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Incremental</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Immutable</p>",
        "correct": true
      }
    ],
    "multiple": false,
    "domain": "AWS Compute",
    "explanation": "<p>The immutable deployment type launches new instances in a new ASG and deploys the version update to these instances before swapping traffic to these instances once healthy. There is zero downtime and a quick rollback in case of failures.</p><img src=\"https://img-c.udemycdn.com/redactor/raw/test_question_description/2022-04-30_04-53-37-af2590b49ad3dfd3ae78903b878f4da4.jpg\" style=\"display: none;\"><span class=\"ud-component--base-components--open-full-size-image\"><div class=\"open-full-size-image--wrapper--R4gIm\" data-purpose=\"open-full-size-image\"><img src=\"https://img-c.udemycdn.com/redactor/raw/test_question_description/2022-04-30_04-53-37-af2590b49ad3dfd3ae78903b878f4da4.jpg\" alt=\"\" loading=\"eager\"><button type=\"button\" class=\"ud-btn ud-btn-medium ud-btn-link ud-heading-sm open-full-size-image--backdrop--Zor3j\"><svg aria-label=\"Larger image\" role=\"img\" focusable=\"false\" class=\"ud-icon ud-icon-large ud-icon-color-neutral\"><use xlink:href=\"#icon-search\"></use></svg></button></div></span><p><strong>CORRECT: </strong>\"Immutable\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Rolling\" is incorrect.</p><p>With a rolling update a few instances are updated at a time (batch), and then the deployment moves onto the next batch once the first batch is healthy. Each batch is taken out of service during deployment leading to downtime. If the update fails, you need to perform an additional rolling update to roll back the changes. This would not be ideal for this production environment.</p><p><strong>INCORRECT:</strong> \"All at once\" is incorrect.</p><p>This would take all instances down at the same time. This is not suitable for a production environment.</p><p><strong>INCORRECT:</strong> \"Incremental\" is incorrect.</p><p>This is not actually a type of deployment model in Elastic Beanstalk.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environmentmgmt-updates-immutable.html\">https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environmentmgmt-updates-immutable.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-elastic-beanstalk/\">https://digitalcloud.training/aws-elastic-beanstalk/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environmentmgmt-updates-immutable.html",
      "https://digitalcloud.training/aws-elastic-beanstalk/"
    ]
  },
  {
    "id": 17,
    "question": "<p>An AWS Lambda function is being developed in a VPC. When a file is added to an Amazon S3 bucket, this Lambda function is triggered, processes the file, and logs the results into a file. These result and log files need to be accessible by other AWS services and on-premises resources.</p><p>What should the developer use to meet these requirements?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Store the result and log files in Amazon S3 and append the new log entries to existing objects.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Keep the result and log files in Amazon Elastic File System (EFS) accessible by Lambda functions.</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Use AWS Glue to consolidate and catalog all result and log files and append log entries.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Use Amazon DynamoDB to store the files and enable DynamoDB Streams to send notifications of changes.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Storage",
    "explanation": "<p>The correct solution is Amazon EFS as it provides a scalable, fully managed elastic NFS file system for AWS Cloud and on-premises resources. EFS can scale to petabytes without disrupting applications, making it suitable for Lambda functions to read/write large amounts of data.</p><p>Furthermore, AWS Lambda can now mount an Amazon EFS file system, making it easy for Lambda functions to read and write large amounts of data or to share data across a fleet of functions.</p><p><strong>CORRECT: </strong>\"Keep the result and log files in Amazon Elastic File System (EFS) accessible by Lambda functions\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Store the result and log files in Amazon S3 and append the new log entries to existing objects\" is incorrect.</p><p>Amazon S3 does not support appending data to existing S3 objects.</p><p><strong>INCORRECT:</strong> \"Use Amazon DynamoDB to store the files and enable DynamoDB Streams to send notifications of changes\" is incorrect.</p><p>While Amazon DynamoDB can store data and Streams can notify services of changes, it is not designed for the type of file storage and sharing described in this scenario.</p><p><strong>INCORRECT:</strong> \"Use AWS Glue to consolidate and catalog all result and log files and append log entries\" is incorrect.</p><p>AWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy for users to prepare and load their data for analytics, but it is not used for direct file storage and sharing.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/services-efs.html\">https://docs.aws.amazon.com/lambda/latest/dg/services-efs.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-efs/\">https://digitalcloud.training/amazon-efs/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/lambda/latest/dg/services-efs.html",
      "https://digitalcloud.training/amazon-efs/"
    ]
  },
  {
    "id": 18,
    "question": "<p>A Developer implemented a static website hosted in Amazon S3 that makes web service requests hosted in Amazon API Gateway and AWS Lambda. The site is showing an error that reads:</p><p>“No ‘Access-Control-Allow-Origin’ header is present on the requested resource. Origin ‘null’ is therefore not allowed access.”</p><p>What should the Developer do to resolve this issue?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Enable cross-origin resource sharing (CORS) on the S3 bucket</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Enable cross-origin resource sharing (CORS) for the method in API Gateway</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Add the Access-Control-Request-Method header to the request</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Add the Access-Control-Request-Headers header to the request</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Storage",
    "explanation": "<p>Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain. In this scenario the S3 bucket is the requestor and is requesting access to resources served by Amazon API Gateway and AWS Lambda. Therefore, the CORS configuration must be enabled on the requested endpoint which is the method in API Gateway.</p><p><strong>CORRECT: </strong>\"Enable cross-origin resource sharing (CORS) for the method in API Gateway\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Enable cross-origin resource sharing (CORS) on the S3 bucket\" is incorrect as CORS must be enabled on the requested endpoint which is API Gateway, not S3.</p><p><strong>INCORRECT:</strong> \"Add the Access-Control-Request-Method header to the request\" is incorrect as this is a request header value that asks permission to use a specific HTTP method.</p><p><strong>INCORRECT:</strong> \"Add the Access-Control-Request-Headers header to the request\" is incorrect as this notifies a server what headers will be sent in a request.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html\">https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-s3-and-glacier/\">https://digitalcloud.training/amazon-s3-and-glacier/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html",
      "https://digitalcloud.training/amazon-s3-and-glacier/"
    ]
  },
  {
    "id": 19,
    "question": "<p>A company runs a popular website behind an Amazon CloudFront distribution that uses an Application Load Balancer as the origin. The Developer wants to set up custom HTTP responses to 404 errors for content that has been removed from the origin that redirects the users to another page.</p><p>The Developer wants to use an AWS Lambda@Edge function that is associated with the current CloudFront distribution to accomplish this goal. The solution must use a minimum amount of resources.</p><p>Which CloudFront event type should the Developer use to invoke the Lambda@Edge function that contains the redirect logic?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Viewer request</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Origin request</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Origin response</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Viewer response</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>When CloudFront receives an HTTP response from the origin server, if there is an origin-response trigger associated with the cache behavior, you can modify the HTTP response to override what was returned from the origin.</p><p>Some common scenarios for updating HTTP responses include the following:</p><p>&nbsp; &nbsp;• Changing the status to set an HTTP 200 status code and creating static body content to return to the viewer when an origin returns an error status code (4xx or 5xx)</p><p>&nbsp; &nbsp;• Changing the status to set an HTTP 301 or HTTP 302 status code, to redirect the user to another website when an origin returns an error status code (4xx or 5xx)</p><p>You can also replace the HTTP responses in viewer and origin request events. However, in this case it is the error response being returned from the origin that must be modified when a 404 error is encountered for a page that has been removed.</p><p><strong>CORRECT: </strong>\"Origin response\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Origin request\" is incorrect as explained above.</p><p><strong>INCORRECT:</strong> \"Viewer response\" is incorrect as explained above.</p><p><strong>INCORRECT:</strong> \"Viewer request\" is incorrect as explained above.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-updating-http-responses.html\">https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-updating-http-responses.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-lambda/\">https://digitalcloud.training/aws-lambda/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-updating-http-responses.html",
      "https://digitalcloud.training/aws-lambda/"
    ]
  },
  {
    "id": 20,
    "question": "<p>A company is creating an application that must support Security Assertion Markup Language (SAML) and authentication with social identity providers. The application must also be authorized to access data in Amazon S3 buckets and Amazon DynamoDB tables.</p><p>Which AWS service or feature will meet these requirements with the LEAST amount of additional coding?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Amazon Cognito identity pools.</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Amazon API Gateway REST API.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Amazon Cognito user pools.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>AWS AppSync GraphQL API.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>Amazon Cognito identity pools (federated identities) enable you to create unique identities for your users and federate them with identity providers. With an identity pool, you can obtain temporary, limited-privilege AWS credentials to access other AWS services.</p><p>Amazon Cognito identity pools support the following identity providers:</p><p> • Public providers: Amazon, Facebook, Google, Apple</p><p> • Amazon Cognito user pools</p><p> • Open ID Connect providers (identity pools)</p><p> • SAML identity providers (identity pools)</p><p> • Developer authenticated identities (identity pools)</p><p>Identity pools are well suited to use cases where you need to authenticate users through one of the above IdPs and then authorize access to AWS services such as Amazon S3 and DynamoDB.</p><p><strong>CORRECT: </strong>\"Amazon Cognito identity pools\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Amazon Cognito user pools\" is incorrect.</p><p>You can use a user pool for authentication but you would then need to use the identity pool for authorization to AWS services. Therefore, this option would require more additional coding.</p><p><strong>INCORRECT:</strong> \"AWS AppSync GraphQL API\" is incorrect.</p><p>There is no need to implement an API for this use case. The developer simply needs a solution for authorization and access control.</p><p><strong>INCORRECT:</strong> \"Amazon API Gateway REST API\" is incorrect.</p><p>There is no need to implement an API for this use case. The developer simply needs a solution for authorization and access control.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-identity.html\">https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-identity.html</a></p><p><a href=\"https://aws.amazon.com/premiumsupport/knowledge-center/cognito-user-pools-identity-pools/\">https://aws.amazon.com/premiumsupport/knowledge-center/cognito-user-pools-identity-pools/</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-cognito/\">https://digitalcloud.training/amazon-cognito/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-identity.html",
      "https://aws.amazon.com/premiumsupport/knowledge-center/cognito-user-pools-identity-pools/",
      "https://digitalcloud.training/amazon-cognito/"
    ]
  },
  {
    "id": 21,
    "question": "<p>A Developer is creating a serverless application. The application looks up information about a customer using a separate Lambda function for each item such as address and phone number. The Developer has created branches in AWS Step Functions for each lookup function.</p><p>How can the Developer optimize the performance, so the lookups complete faster?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use a Map state to iterate over all the items.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Use a Choice state to lookup the specific information required.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use a Parallel state to iterate over all the branches parallel.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Use a Wait state to reduce the wait time for function execution.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Application Integration",
    "explanation": "<p>The Parallel state (\"Type\": \"Parallel\") can be used to create parallel branches of execution in your AWS Step Functions state machine. This will improve the performance of the application by ensuring that all information lookups occur in parallel.</p><p><strong>CORRECT: </strong>\"Use a Parallel state to iterate over all the branches parallel\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Use a Choice state to lookup the specific information required\" is incorrect. This is used to add additional logic but is not required and is unlikely to improve performance.</p><p><strong>INCORRECT:</strong> \"Use a Wait state to reduce the wait time for function execution\" is incorrect. The Wait state delays the state machine from continuing for a specified time.</p><p><strong>INCORRECT:</strong> \"Use a Map state to iterate over all the items\" is incorrect. The Map state executes the same steps for multiple entries of an array in the state input.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-parallel-state.html\">https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-parallel-state.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-application-integration-services/\">https://digitalcloud.training/aws-application-integration-services/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-parallel-state.html",
      "https://digitalcloud.training/aws-application-integration-services/"
    ]
  },
  {
    "id": 22,
    "question": "<p>A start-up organization is launching a new website. Which statement correctly describes how to set up the domain, routing, and health checks in AWS?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use Route 53 to register a domain name and perform routing to the domain and Shield to perform health checks on resources.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Use Route 53 to specify the IP address to perform health checks, register a domain name, and route the internet traffic to domain.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use Route 53 to register a domain name, route the internet traffic to domain, and specify the values to perform health checks on resources.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Use Route 53 to register a domain name and AWS Certificate Manager to perform routing to the domain and Shield to perform health checks on resources.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>Route 53 can be used as a DNS to register a domain name, route the internet traffic, and perform health checks on resources. If being used for all three tasks, the order of register domain, route the traffic, and perform health checks must be sequential. ACM and Shield are not needed for this task.</p><p><strong>CORRECT: </strong>\"Use Route 53 to register a domain name, route the internet traffic to domain, and specify the values to perform health checks on resources\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Use Route 53 to register a domain name and AWS Certificate Manager to perform routing to the domain and Shield to perform health checks on resources\" is incorrect. Route 53 can do all the tasks. ACM and Shield cannot perform these tasks.</p><p><strong>INCORRECT:</strong> \"Use Route 53 to specify the IP address to perform health checks, register a domain name, and route the internet traffic to domain\" is incorrect. Route 53 can be used to perform these tasks but must done in a specific order starting with registering a domain.</p><p><strong>INCORRECT:</strong> \"Use Route 53 to register a domain name and perform routing to the domain and Shield to perform health checks on resources\" is incorrect. Route 53 can do all these tasks. Shield does not perform health checks on resources.</p><p><strong>References</strong>:</p><p><a href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/Welcome.html\">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/Welcome.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-route-53/\">https://digitalcloud.training/amazon-route-53/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/Welcome.html",
      "https://digitalcloud.training/amazon-route-53/"
    ]
  },
  {
    "id": 23,
    "question": "<p>Customers who use a REST API have reported performance issues. A Developer needs to measure the time between when API Gateway receives a request from a client and when it returns a response to the client.</p><p>Which metric should the Developer monitor?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>IntegrationLatency</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Latency</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>CacheHitCount</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>5XXError</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>The Latency metric measures the time between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead.</p><p><strong>CORRECT: </strong>\"Latency\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"IntegrationLatency\" is incorrect. This measures the time between when API Gateway relays a request to the backend and when it receives a response from the backend.</p><p><strong>INCORRECT:</strong> \"CacheHitCount\" is incorrect. This measures the number of requests served from the API cache in a given period.</p><p><strong>INCORRECT:</strong> \"5XXError\" is incorrect. This measures the number of server-side errors captured in a given period.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html\">https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-api-gateway/\">https://digitalcloud.training/amazon-api-gateway/</a></p><p><a href=\"https://digitalcloud.training/amazon-cloudwatch/\">https://digitalcloud.training/amazon-cloudwatch/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html",
      "https://digitalcloud.training/amazon-api-gateway/",
      "https://digitalcloud.training/amazon-cloudwatch/"
    ]
  },
  {
    "id": 24,
    "question": "<p>A developer is planning on using AWS Cloud9 to build a new application. The developer wants to spend minimal time configuring resources. What solution should the developer choose?</p>",
    "corrects": [
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use AWS Toolkit to create an Elastic Compute Cloud (EC2) environment that will provision many of the resources and manage the lifecycle.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Create an SSH environment that will provision many of the resources and manage the lifecycle.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use AWS Toolkit to create an SSH environment that will provision many of the resources and manage the lifecycle.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Create an AWS Cloud9 Elastic Compute Cloud (EC2) environment that will provision many of the resources and manage the lifecycle.</p>",
        "correct": true
      }
    ],
    "multiple": false,
    "domain": "AWS Developer Tools",
    "explanation": "<p>An AWS Cloud9 Elastic Compute Cloud (EC2) Environment has many of the configuration and management taken care of by AWS. This includes creating and managing the instance lifecycle, setting up the Command Line Interface (CLI), and access to packages that are already installed and configured like Git, Node.js, and Python.</p><p><strong>CORRECT</strong>: \"Create an AWS Cloud9 Elastic Compute Cloud (EC2) environment that will provision many of the resources and manage the lifecycle\" is the correct answer (as explained above.)</p><p><strong>INCORRECT</strong>: \"Create an SSH environment that will provision many of the resources and manage the lifecycle\" is incorrect.</p><p>An AWS Cloud9 SSH environment does not provide instance lifecycle management and will require the developer to manually configure or add many features such as the Command Line Interface (CLI) and popular packages like Git, Node.js and Python.</p><p><strong>INCORRECT</strong>: \"Use AWS Toolkit to create an EC2 environment that will provision many of the resources and manage the lifecycle\" is incorrect.</p><p>AWS Toolkit is an extension of the AWS Cloud9 integrated development environment (IDE). It is not used to create an EC2 environment.</p><p><strong>INCORRECT</strong>: \"Use AWS Toolkit to create an SSH environment that will provision many of the resources and manage the lifecycle\" is incorrect.</p><p>AWS Toolkit is an extension of the AWS Cloud9 integrated development environment (IDE). It is not used to create an SSH environment.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/cloud9/latest/user-guide/ec2-env-versus-ssh-env.html\">https://docs.aws.amazon.com/cloud9/latest/user-guide/ec2-env-versus-ssh-env.html</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/cloud9/latest/user-guide/ec2-env-versus-ssh-env.html"
    ]
  },
  {
    "id": 25,
    "question": "<p>A company uses Amazon DynamoDB to store sensitive data that must be encrypted. The company security policy mandates that data must be encrypted before it is submitted to DynamoDB</p><p>How can a Developer meet these requirements?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use AWS Certificate Manager (ACM) to create one certificate for each DynamoDB table.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Use the DynamoDB Encryption Client to enable end-to-end protection using client-side encryption.</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Use the UpdateTable operation to switch to a customer managed customer master key (CMK).</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Use the UpdateTable operation to switch to an AWS managed customer master key (CMK).</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Database",
    "explanation": "<p>In addition to encryption at rest, which is a <em>server-side encryption</em> feature, AWS provides the Amazon DynamoDB Encryption Client. This <em>client-side encryption</em> library enables you to protect your table data before submitting it to DynamoDB. With server-side encryption, your data is encrypted in transit over an HTTPS connection, decrypted at the DynamoDB endpoint, and then re-encrypted before being stored in DynamoDB. Client-side encryption provides end-to-end protection for your data from its source to storage in DynamoDB.</p><p><strong>CORRECT: </strong>\"Use the DynamoDB Encryption Client to enable end-to-end protection using client-side encryption\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Use the UpdateTable operation to switch to a customer managed customer master key (CMK)\" is incorrect. This will not ensure data is encrypted before it is submitted to DynamoDB; to meet this requirement, client-side encryption must be used.</p><p><strong>INCORRECT:</strong> \"Use the UpdateTable operation to switch to an AWS managed customer master key (CMK)\" is incorrect. is will not ensure data is encrypted before it is submitted to DynamoDB; to meet this requirement, client-side encryption must be used.</p><p><strong>INCORRECT:</strong> \"Use AWS Certificate Manager (ACM) to create one certificate for each DynamoDB table\" is incorrect. ACM is used to create SSL/TLS certificates and you cannot attach these to a DynamoDB table.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/services-dynamodb.html\">https://docs.aws.amazon.com/kms/latest/Developerguide/services-dynamodb.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-dynamodb/\">https://digitalcloud.training/amazon-dynamodb/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/kms/latest/developerguide/services-dynamodb.html",
      "https://digitalcloud.training/amazon-dynamodb/"
    ]
  },
  {
    "id": 26,
    "question": "<p>An Amazon DynamoDB table has been created using provisioned capacity. A manager needs to understand whether the DynamoDB table is cost-effective. How can the manager query how much provisioned capacity is actually being used?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Monitor the <code>ConsumedReadCapacityUnits</code> and <code>ConsumedWriteCapacityUnits</code> over a specified time period</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Use Amazon CloudTrail and monitor the <code>DescribeLimits</code> API action</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>1. Use AWS X-Ray to instrument the DynamoDB table and monitor sub segments</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Monitor the <code>ReadThrottleEvents</code> and <code>WriteThrottleEvents</code> metrics for the table</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Database",
    "explanation": "<p>You can monitor Amazon DynamoDB using CloudWatch, which collects and processes raw data from DynamoDB into readable, near real-time metrics. These statistics are retained for a period of time, so that you can access historical information for a better perspective on how your web application or service is performing. By default, DynamoDB metric data is sent to CloudWatch automatically.</p><p>To determine how much of the provisioned capacity is being used you can monitor ConsumedReadCapacityUnits or ConsumedWriteCapacityUnits over the specified time period.</p><p><strong>CORRECT: </strong>\"Monitor the <code>ConsumedReadCapacityUnits</code> and <code>ConsumedWriteCapacityUnits</code> over a specified time period\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Monitor the <code>ReadThrottleEvents</code> and <code>WriteThrottleEvents</code> metrics for the table\" is incorrect as these metrics are used to determine which requests exceed the provisioned throughput limits of a table.</p><p><strong>INCORRECT:</strong> \"Use Amazon CloudTrail and monitor the <code>DescribeLimits</code> API action\" is incorrect as CloudTrail records API actions, not performance metrics.</p><p><strong>INCORRECT:</strong> \"Use AWS X-Ray to instrument the DynamoDB table and monitor subsegments\" is incorrect. DynamoDB does not directly integrate with X-Ray but you can record information in subsegments for downstream requests. This is not, however, a method for monitoring provisioned capacity utilization.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/monitoring-cloudwatch.html\">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/monitoring-cloudwatch.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-dynamodb/\">https://digitalcloud.training/amazon-dynamodb/</a></p><p><a href=\"https://digitalcloud.training/amazon-cloudwatch/\">https://digitalcloud.training/amazon-cloudwatch/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/monitoring-cloudwatch.html",
      "https://digitalcloud.training/amazon-dynamodb/",
      "https://digitalcloud.training/amazon-cloudwatch/"
    ]
  },
  {
    "id": 27,
    "question": "<p>A developer received the following error message during an AWS CloudFormation deployment:</p><p>DELETE_FAILED (The following resource(s) failed to delete: (sg-11223344).)</p><p>Which action should the developer take to resolve this error?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Modify the CloudFormation template to retain the security group resource. Then manually delete the resource after deployment.</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Manually delete the security group. Then execute a change set to force deletion of the CloudFormation stack.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Add a DependsOn attribute to the sg-11223344 resource in the CloudFormation template. Then delete the stack.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Update the logical ID of the security group resource with the security groups ARN. Then delete the stack.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Management & Governance",
    "explanation": "<p>The stack may be stuck in the DELETE_FAILED state because the dependent object (security group), can't be deleted. This can be for many reasons, for example, the security group could have an ENI attached that’s not part of the CloudFormation stack.</p><p>To delete the stack you must choose to delete the stack in the console and then select to retain the resource(s) that failed to delete. This can also be achieved from the AWS CLI:</p><img src=\"https://img-c.udemycdn.com/redactor/raw/test_question_description/2022-04-30_04-35-14-3cedd43a9f1f0a220452f4b399842a88.jpg\" style=\"display: none;\"><span class=\"ud-component--base-components--open-full-size-image\"><div class=\"open-full-size-image--wrapper--R4gIm\" data-purpose=\"open-full-size-image\"><img src=\"https://img-c.udemycdn.com/redactor/raw/test_question_description/2022-04-30_04-35-14-3cedd43a9f1f0a220452f4b399842a88.jpg\" alt=\"\" loading=\"eager\"><button type=\"button\" class=\"ud-btn ud-btn-medium ud-btn-link ud-heading-sm open-full-size-image--backdrop--Zor3j\"><svg aria-label=\"Larger image\" role=\"img\" focusable=\"false\" class=\"ud-icon ud-icon-large ud-icon-color-neutral\"><use xlink:href=\"#icon-search\"></use></svg></button></div></span><p><strong>CORRECT: </strong>\"Modify the CloudFormation template to retain the security group resource. Then manually delete the resource after deployment\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Add a DependsOn attribute to the sg-11223344 resource in the CloudFormation template. Then delete the stack\" is incorrect.</p><p>This creates a dependency for stack creation. It does not assist with resolving the issue that is preventing the stack from deleting successfully.</p><p><strong>INCORRECT:</strong> \"Manually delete the security group. Then execute a change set to force deletion of the CloudFormation stack\" is incorrect.</p><p>You can manually delete the security group. However, you would not then use a change set to continue with the deletion. You would instead simply choose to delete the stack from the console or the CLI.</p><p><strong>INCORRECT:</strong> \"Update the logical ID of the security group resource with the security groups ARN. Then delete the stack\" is incorrect.</p><p>The issue has nothing to do with logical IDs or ARNs. The resource cannot be deleted by CloudFormation so the developer simply needs to choose to retain the resource before continuing with the stack deletion process.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html\">https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-cloudformation/\">https://digitalcloud.training/aws-cloudformation/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html",
      "https://digitalcloud.training/aws-cloudformation/"
    ]
  },
  {
    "id": 28,
    "question": "<p>A Developer has deployed an application that runs on an Auto Scaling group of Amazon EC2 instances. The application data is stored in an Amazon DynamoDB table and records are constantly updated by all instances. An instance sometimes retrieves old data. The Developer wants to correct this by making sure the reads are strongly consistent.</p><p>How can the Developer accomplish this?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Set <code>ConsistentRead</code> to true when calling <code>GetItem</code> </p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Use the <code>GetShardIterator</code> command</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Create a new DynamoDB Accelerator (DAX) table</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Set consistency to strong when calling <code>UpdateTable</code> </p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Database",
    "explanation": "<p>When you request a strongly consistent read, DynamoDB returns a response with the most up-to-date data, reflecting the updates from all prior write operations that were successful.</p><p>The GetItem operation returns a set of attributes for the item with the given primary key. If there is no matching item, GetItem does not return any data and there will be no Item element in the response.</p><p>GetItem provides an eventually consistent read by default. If your application requires a strongly consistent read, set ConsistentRead to true. Although a strongly consistent read might take more time than an eventually consistent read, it always returns the last updated value.</p><p>Therefore, the Developer should set ConsistentRead to true when calling GetItem.</p><p><strong>CORRECT: </strong>\"Set ConsistentRead to true when calling GetItem\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Create a new DynamoDB Accelerator (DAX) table\" is incorrect as DAX is not used to enable strongly consistent reads. DAX is used for improving read performance as it caches data in an in-memory cache.</p><p><strong>INCORRECT:</strong> \"Set consistency to strong when calling UpdateTable\" is incorrect as you cannot use this API action to configure consistency at a table level.</p><p><strong>INCORRECT:</strong> \"Use the GetShardIterator command\" is incorrect as this is not related to DynamoDB, it is related to Amazon Kinesis.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_GetItem.html\">https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_GetItem.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-dynamodb/\">https://digitalcloud.training/amazon-dynamodb/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_GetItem.html",
      "https://digitalcloud.training/amazon-dynamodb/"
    ]
  },
  {
    "id": 29,
    "question": "<p>An organization has a new containerized application that needs to be launched quickly. The team lead has stated to choose the option that would reduce the burden of infrastructure maintenance for the team.</p><p>Which solution best meets this requirement?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use AWS Copilot to provide a template that supports a quick launch of Amazon Elastic Container Service (ECS) applications on Amazon Elastic Compute Cloud (EC2).</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Use AWS Fargate to provide a template that supports a quick launch of Amazon Elastic Container Service (ECS) applications on Amazon Elastic Compute Cloud (EC2).</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use AWS Copilot to provide a template that supports a quick launch of Amazon Elastic Container Service (ECS) applications on AWS Fargate.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Use Amazon Elastic Container Service (ECS) to provide a template that supports a quick launch of AWS Fargate applications on Amazon Elastic Compute Cloud (EC2).</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Compute",
    "explanation": "<p>Copilot can run tasks and services on serverless infrastructures such as AWS Fargate. This can provide the support of containers using ECS and serverless services like Fargate does not require customers to manage.</p><p><strong>CORRECT</strong>: “Use AWS Copilot to provide a template that supports a quick launch of Amazon Elastic Container Service (ECS) applications on AWS Fargate” is the correct answer (as explained above.)</p><p><strong>INCORRECT</strong>: \"Use AWS Copilot to provide a template that supports a quick launch of Amazon Elastic Container Service (ECS) applications on Amazon Elastic Compute Cloud (EC2)\" is incorrect.</p><p>EC2 is not a serverless service and would require additional maintenance and support from the development team.</p><p><strong>INCORRECT</strong>: \"Use AWS Fargate to provide a template that supports a quick launch of Amazon Elastic Container Service (ECS) applications on Amazon Elastic Compute Cloud (EC2)\" is incorrect.</p><p>EC2 is not a serverless service and would require additional maintenance and support from the development team. Fargate is a serverless compute engine. It would not provide a template to support a quick launch.</p><p><strong>INCORRECT</strong>: \"Use Amazon Elastic Container Service (ECS) to provide a template that supports a quick launch of AWS Fargate applications on Amazon Elastic Compute Cloud (EC2)\" is incorrect.</p><p>EC2 is not a serverless service and would require additional maintenance and support from the development team. ECS is a container orchestration service that would not provide a template.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-a-clustered-application-to-amazon-ecs-by-using-aws-copilot.html\">https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-a-clustered-application-to-amazon-ecs-by-using-aws-copilot.html</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/deploy-a-clustered-application-to-amazon-ecs-by-using-aws-copilot.html"
    ]
  },
  {
    "id": 30,
    "question": "<p>A development team is working with Amazon MemoryDB for Redis. The team lead wants to limit the default access of the service-linked role and implement a custom-managed policy instead.</p><p>What needs to be done prior to making this change?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>The team lead would need permission from an AWS Technical Account Manager.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>The team lead would edit the default policy named `AmazonMemoryDBFullAccess`.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>The team lead would need to have permission to call `iam:createServiceLinkedRole`.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>The team lead would have to login as the root user to change the permission setting.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Database",
    "explanation": "<p>Service-linked roles are tied to the resource with predefined permissions. The default policy associated Amazon MemoryDB for Redis is “AmazonMemoryDBFullAccess”. This comes pre-provisioned with permission that the service requires to create a service link that is used to create resources and access other AWS resources and services.</p><p>You might decide not to use the default policy and instead to use a custom-managed policy. In this case, make sure that you have either permissions to call iam:createServiceLinkedRole or that you have created the MemoryDB service-linked role.</p><p><strong>CORRECT</strong>: \"The team lead would need to have permission to call `iam:createServiceLinkedRole`\" is the correct answer (as explained above.)</p><p><strong>INCORRECT</strong>: \"The team lead would have to login as the root user to change the permission setting\" is incorrect.</p><p>The team lead may not be the root user. Logging in and accessing the root user should be limited to the tasks that are necessary and limited to the root user. A Cloud Administrator, for example, could update the IAM roles needed for the team lead to make the appropriate service-linked policy changes.</p><p><strong>INCORRECT</strong>: \"The team lead would need permission from an AWS Technical Account Manager\" is incorrect.</p><p>There are some changes to an account or services that an organization would need to contact their technical account manager to change. An update to the IAM policy or changing a service-linked role is not one of them.</p><p><strong>INCORRECT</strong>: \"The team lead would edit the default policy named `AmazonMemoryDBFullAccess`\" is incorrect.</p><p>AWS managed policies cannot be edited. A custom service policy would need to create and attached with the appropriate IAM role.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/memorydb/latest/devguide/set-up.html\">https://docs.aws.amazon.com/memorydb/latest/devguide/set-up.html</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/memorydb/latest/devguide/set-up.html"
    ]
  },
  {
    "id": 31,
    "question": "<p>An organization wants to ensure that there is minimal latency for their customers on both the east and west coast of the United States. What can they do to provide optimal performance with minimal latency?</p>",
    "corrects": [
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use Amazon Route 53 to direct the traffic based on health checks.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Use Amazon CloudWatch to monitor traffic spikes and identify how to scale horizontally.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use AWS CloudTrail to monitor traffic and identify where requests are coming from and deploy the application to those Regions.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Use Amazon Route 53 with latency-based routing by creating latency records in multiple AWS Regions.</p>",
        "correct": true
      }
    ],
    "multiple": false,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p><strong>CORRECT: </strong>\"Use Amazon Route 53 with latency-based routing by creating latency records in multiple AWS Regions\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Use Amazon Route 53 to direct the traffic based on health checks\" is incorrect. Health checks just show that the resource is healthy, and do not ensure that the best performing endpoint is chosen. Reducing latency is the best option here.</p><p><strong>INCORRECT:</strong> \"Use AWS CloudTrail to monitor traffic and identify where requests are coming from and deploy the application to those Regions\" is incorrect. CloudTrail is used to monitor API calls.</p><p><strong>INCORRECT:</strong> \"Use Amazon CloudWatch to monitor traffic spikes and identify how to scale horizontally\" is incorrect. CloudWatch does monitor spikes in usage, but it is not used to improve latency to end users.</p><p><strong>References</strong>:</p><p><a href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-latency.html\">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-latency.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-route-53/\">https://digitalcloud.training/amazon-route-53/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-latency.html",
      "https://digitalcloud.training/amazon-route-53/"
    ]
  },
  {
    "id": 32,
    "question": "<p>An organization has applied a public certificate to a domain name using AWS Certificate Manager (ACM). What will the browser show to indicate that the site is trusted and is connected via SSL/TLS?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>DNS validation.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>ECDSA key algorithm.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Lock icon on the address bar.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>RSA key algorithm.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>ACM certificates are trusted by all major browsers. When connected by SSL/TLS sites using ACM certificates, this trust is indicated by the lock icon in browser address bar.</p><p><strong>CORRECT: </strong>\"Lock icon on the address bar\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"DNS validation\" is incorrect. DNS validation is used to validate domain ownership and is completed when the certificate is requested.</p><p><strong>INCORRECT:</strong> \"RSA key algorithm\" is incorrect. The RSA key algorithm is selected when requesting the certificate. It is not shown in the browser.</p><p><strong>INCORRECT:</strong> \"ECDSA key algorithm\" is incorrect. The RSA key algorithm is selected when requesting the certificate. It is not shown in the browser.</p><p><strong>References</strong>:</p><p><a href=\"https://docs.aws.amazon.com/acm/latest/userguide/acm-certificate.html\">https://docs.aws.amazon.com/acm/latest/userguide/acm-certificate.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-certificate-manager/\">https://digitalcloud.training/aws-certificate-manager/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/acm/latest/userguide/acm-certificate.html",
      "https://digitalcloud.training/aws-certificate-manager/"
    ]
  },
  {
    "id": 33,
    "question": "<p>An engineer is tasked with creating an AWS CloudFormation template that is capable of automatically determining the AWS Region where it is being deployed.</p><p>What is the MOST efficient method to ascertain the Region during deployment of the template?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Dynamically fetch the Region by referencing the corresponding entry in AWS Systems Manager Parameter Store.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Utilize the AWS::Region pseudo parameter.</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Extract the Region from the AWS::StackId pseudo parameter by applying the Fn::Split intrinsic function.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Request the Region as an input parameter during CloudFormation deployment.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Management & Governance",
    "explanation": "<p>In AWS CloudFormation, the AWS::Region pseudo parameter automatically resolves to the Region where the stack is being created or updated. This makes it the most operationally efficient way to determine the Region in which the template is being deployed, as it doesn't require any additional input, processing, or external service calls.</p><p><strong>CORRECT: </strong>\"Utilize the AWS::Region pseudo parameter\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Request the Region as an input parameter during CloudFormation deployment\" is incorrect.</p><p>This method is not operationally efficient as it relies on manual input from the user each time the template is deployed. It also increases the risk of human error or inconsistencies, especially in multi-region deployments.</p><p><strong>INCORRECT:</strong> \"Extract the Region from the AWS::StackId pseudo parameter by applying the Fn::Split intrinsic function\" is incorrect.</p><p>Although this method technically works because the stack ID contains the region, it's not the most efficient approach. This requires additional processing to extract the region from the stack ID, which makes it less efficient than directly using the AWS::Region pseudo parameter.</p><p><strong>INCORRECT:</strong> \"Dynamically fetch the Region by referencing the corresponding entry in AWS Systems Manager Parameter Store\" is incorrect.</p><p>This method requires an external service and assumes that the region has been correctly stored as a parameter. This adds additional complexity and dependency on another service, making it less efficient than using the built-in AWS::Region pseudo parameter.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/pseudo-parameter-reference.html\">https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/pseudo-parameter-reference.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-cloudformation/\">https://digitalcloud.training/aws-cloudformation/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/pseudo-parameter-reference.html",
      "https://digitalcloud.training/aws-cloudformation/"
    ]
  },
  {
    "id": 34,
    "question": "<p>A developer is using AWS AppSync to develop an application that will be used by a healthcare provider that is subject to HIPAA compliance regulations that require data encryption. The team lead has requested to optimize performance and reduce latency as much as possible.</p><p>How can a developer meet the compliance and team lead requirements?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Set the API Cache for full request caching and adjust the settings for data encryption at rest and in transit.</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Set the API Cache for full request caching and leaving the default encryption settings.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Set the API Cache for “None\" to prevent any changed being made from the default cache settings and adjust the settings for data encryption at rest and in transit.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Set the API Cache for per-resolver caching and leaving the default encryption settings.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Developer Tools",
    "explanation": "<p>AWS AppSync’s API Cache settings provides three options: None, Full request caching, and Per-resolver caching. To meet the team lead’s requirements for high performance and low latency, the cache settings can be configured for full request caching to cache all requests and responses. To meet HIPAA compliance, the settings would be configured for data encryption at rest and in transit.</p><p><strong>CORRECT</strong>: “Set the API Cache for full request caching and adjust the settings for data encryption at rest and in transit” is the correct answer (as explained above.)</p><p><strong>INCORRECT</strong>: \"Set the API Cache for full request caching and leaving the default encryption settings\" is incorrect. The API Cache set to full request caching is correct.</p><p>The default settings for API Cache are for no encryption. To meet HIPAA compliance, data should be protected, and encryption should be enabled for in transit and at rest.</p><p><strong>INCORRECT</strong>: “Set the API Cache for “None\" to prevent any changed being made from the default cache settings and adjust the settings for data encryption at rest and in transit\" is incorrect.</p><p>“None” is the default setting for the API Cache and would not cache any requests and responses. This would not meet the goal of optimizing performance and decreasing latency. The change in the encryption settings is correct.</p><p><strong>INCORRECT</strong>: \"Set the API Cache for per-resolver caching and leaving the default encryption settings \" is incorrect.</p><p>The per-resolver caching will only cache specific calls. The default encryption leaves the data unencrypted which does not meet the HIPAA requirements.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/appsync/latest/devguide/enabling-caching.html\">https://docs.aws.amazon.com/appsync/latest/devguide/enabling-caching.html</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/appsync/latest/devguide/enabling-caching.html"
    ]
  },
  {
    "id": 35,
    "question": "<p>An organization is modernizing a software solution by migrating its database operations from Amazon EC2 instances to a serverless architecture. The software utilizes an Amazon RDS for PostgreSQL database and operates within a single VPC on AWS. Both the software and the database are currently deployed on a private subnet in the VPC. The organization needs to enable AWS Lambda functions to interact with the PostgreSQL database.</p><p>Which solution would securely satisfy these needs?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Configure the Lambda functions to connect directly to the RDS instance by using its public IP address.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Place the Lambda functions within the same VPC as the RDS instance and ensure they have an appropriate security group rule to access the RDS instance.</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Deploy an AWS AppRunner service in the VPC, which will host the Lambda functions and connect them to the RDS instance.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Establish an AWS Direct Connect link between the Lambda functions and the RDS instance.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Compute",
    "explanation": "<p>Placing the Lambda functions within the same VPC as the RDS instance and ensuring they have an appropriate security group rule to access the RDS instance would allow the Lambda functions to interact with the PostgreSQL database without exposing the database to the public internet, keeping the operations secure and in line with the existing infrastructure.</p><p><strong>CORRECT: </strong>\"Place the Lambda functions within the same VPC as the RDS instance and ensure they have an appropriate security group rule to access the RDS instance\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Configure the Lambda functions to connect directly to the RDS instance by using its public IP address\" is incorrect.</p><p>Configuring the Lambda functions to connect directly to the RDS instance using its public IP address is insecure and goes against best practices for keeping resources in private subnets isolated.</p><p><strong>INCORRECT:</strong> \"Deploy an AWS AppRunner service in the VPC, which will host the Lambda functions and connect them to the RDS instance\" is incorrect.</p><p>AWS App Runner is primarily designed for building, deploying, and scaling containerized applications quickly, and is not suited to hosting Lambda functions or establishing connections with an RDS instance.</p><p><strong>INCORRECT:</strong> \"Establish an AWS Direct Connect link between the Lambda functions and the RDS instance\" is incorrect.</p><p>AWS Direct Connect is used for establishing a dedicated network connection from your premises to AWS and would not be applicable or necessary for Lambda functions trying to connect to an RDS instance within the same AWS environment.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html\">https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-lambda/\">https://digitalcloud.training/aws-lambda/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html",
      "https://digitalcloud.training/aws-lambda/"
    ]
  },
  {
    "id": 36,
    "question": "<p>An application must be refactored for the cloud. The application data is stored in an Amazon DynamoDB table and is processed by a Lambda function which prepares the data for analytics. The data processing currently takes place once a day, but the data analysts require it to be performed in near-real time.</p><p>Which architecture pattern could be used to enable the data to be processed as it is received?</p>",
    "corrects": [
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use a fan-out architecture.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Use a scheduled architecture.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use a microservices architecture.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Use an event-driven architecture.</p>",
        "correct": true
      }
    ],
    "multiple": false,
    "domain": "AWS Compute",
    "explanation": "<p>An event driven architecture will ensure that the records are processed as they are received. This can be achieved by creating a DynamoDB Stream for the existing table and then configuring the Lambda function to retrieve messages from the stream. This would be an event-driven architecture as the event (a record being written to the stream) causes the processing layer to do work.</p><p><strong>CORRECT: </strong>\"Use an event-driven architecture\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Use a microservices architecture\" is incorrect.</p><p>A microservices architecture is where you have many small individual components of an application that are loosely coupled. Though the architecture described may have components of a microservices architecture, this is not the defining characteristic that meets the requirement of near-real time processing.</p><p><strong>INCORRECT:</strong> \"Use a fan-out architecture\" is incorrect.</p><p>An example of a fan-out architecture is using SNS to send a single notification to many SQS queues.</p><p><strong>INCORRECT:</strong> \"Use a scheduled architecture\" is incorrect.</p><p>A scheduled architecture would not process events as they occur. It would only process them on a fixed schedule.</p><p><strong>References:</strong></p><p><a href=\"https://aws.amazon.com/event-driven-architecture/\">https://aws.amazon.com/event-driven-architecture/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://aws.amazon.com/event-driven-architecture/"
    ]
  },
  {
    "id": 37,
    "question": "<p>A company is deploying a serverless application on AWS, using an AWS Lambda function for handling customer orders. This function utilizes an external HTTP API for processing payments, which occasionally times out. The requirement is to notify the support team via an existing Amazon SNS topic when the error rate of this API surpasses 10% per hour.</p><p>How can this be achieved?</p>",
    "corrects": [
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Configure the AWS Lambda function to directly send alerts to the SNS topic when there is a timeout.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Enable AWS CloudTrail to monitor the Lambda function and send alerts to the SNS topic when the error rate exceeds 10%.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use AWS X-Ray to monitor the error rate and configure it to send alerts through the SNS topic.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Implement Amazon CloudWatch Metrics with a custom threshold and link it to the existing SNS topic.</p>",
        "correct": true
      }
    ],
    "multiple": false,
    "domain": "AWS Management & Governance",
    "explanation": "<p>Amazon CloudWatch Metrics can monitor and track API error rates and can be configured to trigger an alert when a particular threshold is surpassed. By linking this to the existing Amazon SNS topic, the support team can be notified in near real-time when the payment processing external API error rate exceeds 10% of the total number of transactions in an hour.</p><p><strong>CORRECT: </strong>\"Implement Amazon CloudWatch Metrics with a custom threshold and link it to the existing SNS topic\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Use AWS X-Ray to monitor the error rate and configure it to send alerts through the SNS topic\" is incorrect.</p><p>AWS X-Ray is more suited for tracing applications to debug and analyze individual user paths, rather than for real-time alerting on API error rates.</p><p><strong>INCORRECT:</strong> \"Configure the AWS Lambda function to directly send alerts to the SNS topic when there is a timeout\" is incorrect.</p><p>Modifying the Lambda function to directly send alerts may increase the complexity of the function and may not be as reliable or timely as using a dedicated monitoring service like CloudWatch.</p><p><strong>INCORRECT:</strong> \"Enable AWS CloudTrail to monitor the Lambda function and send alerts to the SNS topic when the error rate exceeds 10%\" is incorrect.</p><p>AWS CloudTrail is a service that provides event history of your AWS account activity, including actions taken through the AWS Management Console, AWS SDKs, command-line tools, and other AWS services. It is not designed to monitor error rates of APIs or Lambda functions and trigger alerts based on those.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html\">https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-cloudwatch/\">https://digitalcloud.training/amazon-cloudwatch/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html",
      "https://digitalcloud.training/amazon-cloudwatch/"
    ]
  },
  {
    "id": 38,
    "question": "<p>A development team using AWS Amplify is testing new features for an application. How can the team test the features with the current production code without impacting the last published application version?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Connect a new branch that will deploy a version named https://main.applicationId.amplifyapp.com to test new features.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Connect the production environment into AWS Cloud9 and test the features after committing them.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Connect a new branch that will deploy a version named https://dev.applicationId.amplifyapp.com to test new features.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Connect the production environment into AWS Cloud9 and test the features after publishing them.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Developer Tools",
    "explanation": "<p>Features testing on an application should not be done on production code. AWS Amplify supports connecting branches from the production code environment that will clone a repository so that features can be developed, tested and rolled back, if necessary, without impacting the latest version of the published application.</p><p><strong>CORRECT</strong>: “Connect a new branch that will deploy a version named https://dev.applicationId.amplifyapp.com to test new features” is the correct answer (as explained above.)</p><p><strong>INCORRECT</strong>: \"Connect a new branch that will deploy a version named https://main.applicationId.amplifyapp.com to test new features\" is incorrect.</p><p>The “main” branch indicated in the URL indicates this is the main production environment and not the one to test features on.</p><p><strong>INCORRECT</strong>: “Connect the production environment into AWS Cloud9 and test the features after publishing them\" is incorrect.</p><p>AWS Cloud9 is an IDE that can be used to develop new features if the development chooses to use it. Other IDEs can also be used and integrated in the development process. Once features have passed all the checks, it can be pushed.</p><p><strong>INCORRECT</strong>: \"Connect the production environment into AWS Cloud9 and test the features after committing them\" is incorrect.</p><p>AWS Cloud9 is an IDE that can be used to develop new features if the development chooses to use it. Other IDEs can also be used and integrated in the development process. Committing the features captures a snapshot of the staged changes.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/amplify/latest/userguide/multi-environments.html\">https://docs.aws.amazon.com/amplify/latest/userguide/multi-environments.html</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/amplify/latest/userguide/multi-environments.html"
    ]
  },
  {
    "id": 39,
    "question": "<p>A serverless application uses an IAM role to authenticate and authorize access to an Amazon DynamoDB table. A Developer is troubleshooting access issues affecting the application. The Developer has access to the IAM role that the application is using.</p><p>Which of the following commands will help the Developer to test the role permissions using the AWS CLI?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>aws sts assume-role</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>aws iam get-role-policy</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>aws sts get-session-token</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>aws dynamodb describe-endpoints</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>The AWS CLI “aws sts assume role” command will enable the Developer to assume the role and gain temporary security credentials. The Developer can then use those security credentials to troubleshoot access issues that are affecting the application.</p><p><strong>CORRECT: </strong>\"aws sts assume-role\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"aws sts get-session-token\" is incorrect. This is used to get temporary credentials for an AWS account or IAM user. It can subsequently be used to call the assume-role API.</p><p><strong>INCORRECT:</strong> \"aws iam get-role-policy\" is incorrect. This command retrieves the specified inline policy document that is embedded with the specified IAM role.</p><p><strong>INCORRECT:</strong> \"aws dynamodb describe-endpoints\" is incorrect. This command returns the regional endpoint information.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/cli/latest/reference/sts/assume-role.html\">https://docs.aws.amazon.com/cli/latest/reference/sts/assume-role.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-dynamodb/\">https://digitalcloud.training/amazon-dynamodb/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/cli/latest/reference/sts/assume-role.html",
      "https://digitalcloud.training/amazon-dynamodb/"
    ]
  },
  {
    "id": 40,
    "question": "<p>A Developer has created an Amazon S3 bucket and uploaded some objects that will be used for a publicly available static website. What steps MUST be performed to configure the bucket as a static website? (Select TWO.)</p>",
    "corrects": [
      2,
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Upload an index and error document and enter the name of the index and error documents when enabling static website hosting</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Upload an index document and enter the name of the index document when enabling static website hosting</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Upload a certificate from AWS Certificate Manager</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Enable public access and grant everyone the <code>s3:GetObject </code>permissions</p>",
        "correct": true
      },
      {
        "id": 5,
        "answer": "<p>Create an object access control list (ACL) granting <code>READ</code> permissions to the <code>AllUsers</code> group</p>",
        "correct": false
      }
    ],
    "multiple": true,
    "domain": "AWS Storage",
    "explanation": "<p>You can use Amazon S3 to host a static website. On a <em>static</em> website, individual webpages include static content. They might also contain client-side scripts.</p><p>To host a static website on Amazon S3, you configure an Amazon S3 bucket for website hosting and then upload your website content to the bucket. When you configure a bucket as a static website, you enable static website hosting, set permissions, and add an index document.</p><p>When you enable static website hosting for your bucket, you enter the name of the index document (for example, index.html). After you enable static website hosting for your bucket, you upload an HTML file with the index document name to your bucket. Note that an error document is optional.</p><p>To provide permissions, it is necessary to disable “block public access” settings and then create a bucket policy that grants everyone the <code>s3:GetObject</code> permission. For example:</p><div class=\"ud-component--base-components--code-block\"><div><pre class=\"prettyprint linenums prettyprinted\" role=\"presentation\" style=\"\"><ol class=\"linenums\"><li class=\"L0\"><span class=\"pun\">{</span></li><li class=\"L1\"><span class=\"str\">\"Version\"</span><span class=\"pun\">:</span><span class=\"pln\"> </span><span class=\"str\">\"2012-10-17\"</span><span class=\"pun\">,</span></li><li class=\"L2\"><span class=\"str\">\"Statement\"</span><span class=\"pun\">:</span><span class=\"pln\"> </span><span class=\"pun\">[</span></li><li class=\"L3\"><span class=\"pun\">{</span></li><li class=\"L4\"><span class=\"str\">\"Sid\"</span><span class=\"pun\">:</span><span class=\"pln\"> </span><span class=\"str\">\"PublicReadGetObject\"</span><span class=\"pun\">,</span></li><li class=\"L5\"><span class=\"str\">\"Effect\"</span><span class=\"pun\">:</span><span class=\"pln\"> </span><span class=\"str\">\"Allow\"</span><span class=\"pun\">,</span></li><li class=\"L6\"><span class=\"str\">\"Principal\"</span><span class=\"pun\">:</span><span class=\"pln\"> </span><span class=\"str\">\"*\"</span><span class=\"pun\">,</span></li><li class=\"L7\"><span class=\"str\">\"Action\"</span><span class=\"pun\">:</span><span class=\"pln\"> </span><span class=\"pun\">[</span></li><li class=\"L8\"><span class=\"str\">\"s3:GetObject\"</span></li><li class=\"L9\"><span class=\"pun\">],</span></li><li class=\"L0\"><span class=\"str\">\"Resource\"</span><span class=\"pun\">:</span><span class=\"pln\"> </span><span class=\"pun\">[</span></li><li class=\"L1\"><span class=\"str\">\"arn:aws:s3:::example.com/*\"</span></li><li class=\"L2\"><span class=\"pun\">]</span></li><li class=\"L3\"><span class=\"pun\">}</span></li><li class=\"L4\"><span class=\"pun\">]</span></li><li class=\"L5\"><span class=\"pun\">}</span></li></ol></pre></div></div><p><strong>CORRECT: </strong>\"Upload an index document and enter the name of the index document when enabling static website hosting\" is a correct answer.</p><p><strong>CORRECT: </strong>\"Enable public access and grant everyone the <code>s3:GetObject</code> permissions\" is also a correct answer.</p><p><strong>INCORRECT:</strong> \"Upload an index and error document and enter the name of the index and error documents when enabling static website hosting\" is incorrect as the error document is optional and the question specifically asks for the steps that MUST be completed.</p><p><strong>INCORRECT:</strong> \"Create an object access control list (ACL) granting <code>READ</code> permissions to the <code>AllUsers </code>group\" is incorrect. This may be necessary if the bucket objects are not owned by the bucket owner but the question states that the Developer created the bucket and uploaded the objects and so must be the object owner.</p><p><strong>INCORRECT:</strong> \"Upload a certificate from AWS Certificate Manager\" is incorrect as this is not supported or necessary for static websites on Amazon S3.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html\">https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-s3-and-glacier/\">https://digitalcloud.training/amazon-s3-and-glacier/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html",
      "https://digitalcloud.training/amazon-s3-and-glacier/"
    ]
  },
  {
    "id": 41,
    "question": "<p>An application running on Amazon EC2 generates a large number of small files (1KB each) containing personally identifiable information that must be converted to ciphertext. The data will be stored on a proprietary network-attached file system. What is the SAFEST way to encrypt the data using AWS KMS?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Encrypt the data directly with a customer managed customer master key</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Create a data encryption key from a customer master key and encrypt the data with the customer master key</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Create a data encryption key from a customer master key and encrypt the data with the data encryption key</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Encrypt the data directly with an AWS managed customer master key</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>With AWS KMS you can encrypt files directly with a customer master key (CMK). A CMK can encrypt up to 4KB (4096 bytes) of data in a single encrypt, decrypt, or reencrypt operation. As CMKs cannot be exported from KMS this is a very safe way to encrypt small amounts of data.</p><p><em>Customer managed CMKs</em> are CMKs in your AWS account that you create, own, and manage. You have full control over these CMKs, including establishing and maintaining their <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/control-access.html\">key policies, IAM policies, and grants</a>, <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/enabling-keys.html\">enabling and disabling</a> them, <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html\">rotating their cryptographic material</a>, <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/tagging-keys.html\">adding tags</a>, <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/programming-aliases.html\">creating aliases</a> that refer to the CMK, and <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/deleting-keys.html\">scheduling the CMKs for deletion</a>.</p><p><em>AWS managed CMKs</em> are CMKs in your account that are created, managed, and used on your behalf by an AWS service that is integrated with AWS KMS. Some AWS services support only an AWS managed CMK. In this example the Amazon EC2 instance is saving files on a proprietary network-attached file system and this will not have support for AWS managed CMKs.</p><p><em>Data keys</em> are encryption keys that you can use to encrypt data, including large amounts of data and other data encryption keys. You can use AWS KMS CMKs to generate, encrypt, and decrypt data keys. However, AWS KMS does not store, manage, or track your data keys, or perform cryptographic operations with data keys. You must use and manage data keys outside of AWS KMS – this is potentially less secure as you need to manage the security of these keys.</p><p><strong>CORRECT: </strong>\"Encrypt the data directly with a customer managed customer master key\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Create a data encryption key from a customer master key and encrypt the data with the data encryption key\" is incorrect as this is not the most secure option here as you need to secure the data encryption key outside of KMS. It is also unwarranted as you can use a CMK directly to encrypt files up to 4KB in size.</p><p><strong>INCORRECT:</strong> \"Create a data encryption key from a customer master key and encrypt the data with the customer master key\" is incorrect as the creation of the data encryption key is of no use here. It does not necessarily pose a security risk as the data key hasn’t been used (and you can use the CMK to encrypt the data), however this is not the correct process to follow.</p><p><strong>INCORRECT:</strong> \"Encrypt the data directly with an AWS managed customer master key\" is incorrect as the network-attached file system is proprietary and therefore will not be supported by AWS managed CMKs.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html\">https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-kms/\">https://digitalcloud.training/aws-kms/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/kms/latest/developerguide/control-access.html",
      "https://docs.aws.amazon.com/kms/latest/developerguide/enabling-keys.html",
      "https://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html",
      "https://docs.aws.amazon.com/kms/latest/developerguide/tagging-keys.html",
      "https://docs.aws.amazon.com/kms/latest/developerguide/programming-aliases.html",
      "https://docs.aws.amazon.com/kms/latest/developerguide/deleting-keys.html",
      "https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html",
      "https://digitalcloud.training/aws-kms/"
    ]
  },
  {
    "id": 42,
    "question": "<p>An application runs on a fleet of Amazon EC2 instances in an Auto Scaling group. The application stores data in an Amazon DynamoDB table and all instances make updates to the table. When querying data, EC2 instances sometimes retrieve stale data. The Developer needs to update the application to ensure the most up-to-date data is retrieved for all queries.</p><p>How can the Developer accomplish this?</p>",
    "corrects": [
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use the TransactWriteItems API when issuing PutItem actions.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Use the UpdateGlobalTable API to create a global secondary index.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Cache the database writes using Amazon DynamoDB Accelerator.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Set the ConsistentRead parameter to true when calling GetItem.</p>",
        "correct": true
      }
    ],
    "multiple": false,
    "domain": "AWS Database",
    "explanation": "<p>DynamoDB supports <em>eventually consistent</em> and <em>strongly consistent</em> reads. When using eventually consistent reads the response might not reflect the results of a recently completed write operation. The response might include some stale data.</p><p>When using strongly consistent reads DynamoDB returns a response with the most up-to-date data, reflecting the updates from all prior write operations that were successful.</p><p>DynamoDB uses eventually consistent reads unless you specify otherwise. Read operations (such as GetItem, Query, and Scan) provide a ConsistentRead parameter. If you set this parameter to true, DynamoDB uses strongly consistent reads during the operation.</p><p><strong>CORRECT: </strong>\"Set the ConsistentRead parameter to true when calling GetItem\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Cache the database writes using Amazon DynamoDB Accelerator\" is incorrect. DynamoDB DAX caches items from DynamoDB to improve read performance but will not ensure the latest data is retrieved.</p><p><strong>INCORRECT:</strong> \"Use the TransactWriteItems API when issuing PutItem actions\" is incorrect. This operation is used to group transactions in an all-or-nothing update.</p><p><strong>INCORRECT:</strong> \"Use the UpdateGlobalTable API to create a global secondary index\" is incorrect. A GSI does not assist in any way in this solution.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html\">https://docs.aws.amazon.com/amazondynamodb/latest/Developerguide/HowItWorks.ReadConsistency.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-dynamodb/\">https://digitalcloud.training/amazon-dynamodb/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html",
      "https://digitalcloud.training/amazon-dynamodb/"
    ]
  },
  {
    "id": 43,
    "question": "<p>A team of Developers are working on a shared project and need to be able to collaborate on code. The shared application code must be encrypted at rest, stored on a highly available and durable architecture, and support multiple versions and batch change tracking.</p><p>Which AWS service should the Developer use?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>AWS CodeCommit</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>AWS CodeBuild</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Amazon S3</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>AWS Cloud9</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Developer Tools",
    "explanation": "<p>AWS CodeCommit is a fully managed source control service that hosts secure Git-based repositories. It makes it easy for teams to collaborate on code in a secure and highly scalable ecosystem. AWS CodeCommit automatically encrypts your files in transit and at rest.</p><p>AWS CodeCommit helps you collaborate on code with teammates via pull requests, branching, and merging. You can implement workflows that include code reviews and feedback by default, and control who can make changes to specific branches.</p><p><strong>CORRECT: </strong>\"AWS CodeCommit\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"AWS CodeBuild\" is incorrect. AWS CodeBuild is a fully managed continuous integration service that compiles source code, runs tests, and produces software packages</p><p><strong>INCORRECT:</strong> \"Amazon S3\" is incorrect. Amazon S3 is an object-based storage system and does not support the features required here.</p><p><strong>INCORRECT:</strong> \"AWS Cloud9\" is incorrect. AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser.</p><p><strong>References:</strong></p><p><a href=\"https://aws.amazon.com/codecommit/\">https://aws.amazon.com/codecommit/</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-developer-tools/\">https://digitalcloud.training/aws-developer-tools/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://aws.amazon.com/codecommit/",
      "https://digitalcloud.training/aws-developer-tools/"
    ]
  },
  {
    "id": 44,
    "question": "<p>A developer is working on a serverless application using AWS Cloud Development Kit (AWS CDK) and intends to set up several AWS Lambda functions and Amazon API Gateway APIs during the creation of an AWS CloudFormation stack. The developer's local machine is equipped with AWS Serverless Application Model (AWS SAM) and the AWS CDK.</p><p>What is the best way for the developer to locally test a particular Lambda function?</p>",
    "corrects": [
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use the AWS CDK command line to locally run the Lambda function.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Test the Lambda function through the AWS Management Console.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Directly execute the Lambda function on the local machine.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Use the sam local invoke command specifying the specific Lambda function.</p>",
        "correct": true
      }
    ],
    "multiple": false,
    "domain": "AWS Compute",
    "explanation": "<p>AWS SAM CLI is a developer tool that allows you to locally test and debug your AWS Lambda functions defined by AWS Serverless Application Model (SAM) templates. Using the <strong>sam local invoke</strong> command with the specific Lambda function as an argument, you can execute the function locally.</p><p><strong>CORRECT: </strong>\"Use the sam local invoke command specifying the specific Lambda function\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Test the Lambda function through the AWS Management Console\" is incorrect.</p><p>The AWS Management Console allows you to create and manage AWS Lambda functions but doesn't provide a feature to test functions locally.</p><p><strong>INCORRECT:</strong> \"Use the AWS CDK command line to locally run the Lambda function\" is incorrect.</p><p>AWS CDK is a software development framework to define cloud infrastructure in code and provision it through AWS CloudFormation, but it doesn't allow local execution of Lambda functions.</p><p><strong>INCORRECT:</strong> \"Directly execute the Lambda function on the local machine\" is incorrect.</p><p>AWS Lambda functions cannot be executed directly on a local machine without a local testing tool like AWS SAM CLI.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-using-invoke.html\">https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-using-invoke.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-sam/\">https://digitalcloud.training/aws-sam/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-using-invoke.html",
      "https://digitalcloud.training/aws-sam/"
    ]
  },
  {
    "id": 45,
    "question": "<p>A developer wants to use a cron job to schedule key rotation for an Amazon RDS database. What steps should the developer take to complete this task?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use AWS Systems Manager (SSM) Parameter Store to create a managed rotation under the Rotation Schedule and schedule the time for the automatic rotation using a cron expression.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Use AWS Secrets Manager to create a managed rotation under the Rotation Schedule and schedule the time for the automatic rotation using a cron expression.</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Use AWS Relational Database Service to create a managed rotation under the Rotation Schedule and schedule the time for the automatic rotation using a cron expression.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Use AWS Identity and Access Management (IAM) to create a managed rotation under the Rotation Schedule and schedule the time for the automatic rotation using a cron expression.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p><em>Rotation</em> is the process of periodically updating a secret. When you rotate a secret, you update the credentials in both the secret and the database or service. In Secrets Manager, you can set up automatic rotation for your secrets.</p><p>Some services offer <em>managed rotation</em>, where the service configures and manages rotation for you. With managed rotation, you don't use an AWS Lambda function to update the secret and the credentials in the database. Amazon RDS can be used with managed rotation.</p><p><strong>CORRECT: </strong>\"Use AWS Secrets Manager to create a managed rotation under the Rotation Schedule and schedule the time for the automatic rotation using a cron expression\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Use AWS Identity and Access Management (IAM) to create a managed rotation under the Rotation Schedule and schedule the time for the automatic rotation using a cron expression\" is incorrect. IAM is an identity and management services to help assign permissions to users, groups and roles. It does not manage secrets such as passwords or access keys.</p><p><strong>INCORRECT:</strong> \"Use AWS Relational Database Service to create a managed rotation under the Rotation Schedule and schedule the time for the automatic rotation using a cron expression\" is incorrect. RDS is a used to simplify the set-up of relational databases. It is not used for managing secrets.</p><p><strong>INCORRECT:</strong> \"Use AWS Systems Manager Parameter Store to create a managed rotation under the Rotation Schedule and schedule the time for the automatic rotation using a cron expression\" is incorrect. The SSM Parameter store does not use cron jobs to manage rotations.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotate-secrets_schedule.html\">https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotate-secrets_schedule.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-secrets-manager/\">https://digitalcloud.training/aws-secrets-manager/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/secretsmanager/latest/userguide/rotate-secrets_schedule.html",
      "https://digitalcloud.training/aws-secrets-manager/"
    ]
  },
  {
    "id": 46,
    "question": "<p>A developer needs to create a serverless application that uses an event-driven architecture.</p><p>How can the developer configure the application to automatically receive and process events?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Create an Amazon SNS topic and an AWS Lambda function. Configure an HTTP endpoint on the Lambda function and subscribe the HTTP endpoint to the SNS topic. Submit events to the SNS topic.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Create an Amazon SNS topic and an AWS Lambda function. Subscribe the Lambda function to the SNS topic and submit events to the SNS topic.</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Create an Amazon SQS queue and publish events to the queue. Configure an Amazon EC2 instance to poll the queue and consume the messages.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Create an Amazon SQS topic and an Amazon EC2 instance. Subscribe the instance to the SNS topic and submit events to the topic.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Application Integration",
    "explanation": "<p>You can use a Lambda function to process Amazon Simple Notification Service (Amazon SNS) notifications. Amazon SNS supports Lambda functions as a target for messages sent to a topic. You can subscribe your function to topics in the same account or in other AWS accounts.</p><p>When an event is submitted to the SNS topic it will be sent to AWS Lambda which can then process the event. This is an example of a simple event-driven architecture.</p><img src=\"https://img-c.udemycdn.com/redactor/raw/test_question_description/2022-04-30_04-48-58-2a40f82996630ba43c79a0d366709ab4.jpg\" style=\"display: none;\"><span class=\"ud-component--base-components--open-full-size-image\"><div class=\"open-full-size-image--wrapper--R4gIm\" data-purpose=\"open-full-size-image\"><img src=\"https://img-c.udemycdn.com/redactor/raw/test_question_description/2022-04-30_04-48-58-2a40f82996630ba43c79a0d366709ab4.jpg\" alt=\"\" loading=\"eager\"><button type=\"button\" class=\"ud-btn ud-btn-medium ud-btn-link ud-heading-sm open-full-size-image--backdrop--Zor3j\"><svg aria-label=\"Larger image\" role=\"img\" focusable=\"false\" class=\"ud-icon ud-icon-large ud-icon-color-neutral\"><use xlink:href=\"#icon-search\"></use></svg></button></div></span><p><strong>CORRECT: </strong>\"Create an Amazon SNS topic and an AWS Lambda function. Subscribe the Lambda function to the SNS topic and submit events to the SNS topic\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Create an Amazon SQS queue and publish events to the queue. Configure an Amazon EC2 instance to poll the queue and consume the messages\" is incorrect.</p><p>Amazon EC2 is not a serverless service so cannot if the application must be serverless.</p><p><strong>INCORRECT:</strong> \"Create an Amazon SQS topic and an Amazon EC2 instance. Subscribe the instance to the SNS topic and submit events to the topic\" is incorrect.</p><p>EC2 is not serverless and cannot be subscribed to an SNS topic.</p><p><strong>INCORRECT:</strong> \"Create an Amazon SNS topic and an AWS Lambda function. Configure an HTTP endpoint on the Lambda function and subscribe the HTTP endpoint to the SNS topic. Submit events to the SNS topic\" is incorrect.</p><p>An HTTP endpoint is not required for the serverless application. Lambda can be subscribed directly to an SNS topic.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/with-sns.html\">https://docs.aws.amazon.com/lambda/latest/dg/with-sns.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-application-integration-services/\">https://digitalcloud.training/aws-application-integration-services/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/lambda/latest/dg/with-sns.html",
      "https://digitalcloud.training/aws-application-integration-services/"
    ]
  },
  {
    "id": 47,
    "question": "<p>A developer is configuring health checks using Amazon Route 53 and needs to set values to determine the health of critical endpoints. What is the parameter that Amazon Route 53 reviews before deciding if an endpoint is unhealthy?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>failure threshold.</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>fault tolerance.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>network response.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>latency.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>The failure threshold is specified by the AWS customer. A failure is when the endpoint does not respond to a request.</p><p><strong>CORRECT: </strong>\"failure threshold\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"latency\" is incorrect. Latency is not a parameter that Route 53 uses to determine if an endpoint is healthy.</p><p><strong>INCORRECT:</strong> \"fault tolerance\" is incorrect. Fault tolerance is not a parameter that Route 53 uses to determine if an endpoint is healthy.</p><p><strong>INCORRECT:</strong> \"network response\" is incorrect. Network response is not a parameter that Route 53 uses to determine if an endpoint is healthy.</p><p><strong>References</strong>:</p><p><a href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/welcome-health-checks.html\">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/welcome-health-checks.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-route-53/\">https://digitalcloud.training/amazon-route-53/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/welcome-health-checks.html",
      "https://digitalcloud.training/amazon-route-53/"
    ]
  },
  {
    "id": 48,
    "question": "<p>An application stores data in Amazon RDS and uses Amazon ElastiCache to improve read performance. The developer has configured ElastiCache to update the cache immediately after any writes to the primary database.</p><p>What will be the result of this approach to caching?</p>",
    "corrects": [
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Load on the RDS database instance will increase because the cache is updated for every database update.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Caching will slow performance of the read queries because the cache is updated when the cache cannot find the requested data.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>There is a cache miss penalty because the cache is updated only after a cache miss, resulting in response latency.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>The cache will become large and expensive because the infrequently requested data is also written to the cache.</p>",
        "correct": true
      }
    ],
    "multiple": false,
    "domain": "AWS Database",
    "explanation": "<p>The ElastiCache deployment is using a write-through caching strategy. The write-through strategy adds data or updates data in the cache whenever data is written to the database. This means data in the cache is never stale. There is a write penalty, but not a read penalty (in terms of latency added).</p><p>However, with a write-through strategy, most data are never read so the cache can become large and expensive. Adding a TTL to records can assist with this.</p><p><strong>CORRECT: </strong>\"The cache will become large and expensive because the infrequently requested data is also written to the cache\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Caching will slow performance of the read queries because the cache is updated when the cache cannot find the requested data\" is incorrect.</p><p>This is true of a lazy loading strategy. With a write-through strategy there is a write penalty, but not a read penalty.</p><p><strong>INCORRECT:</strong> \"Load on the RDS database instance will increase because the cache is updated for every database update\" is incorrect.</p><p>There is still only one write to the RDS database instance.</p><p><strong>INCORRECT:</strong> \"There is a cache miss penalty because the cache is updated only after a cache miss, resulting in response latency\" is incorrect.</p><p>This is a description of a lazy loading strategy, not a write-through strategy.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/Strategies.html\">https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/Strategies.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-elasticache/\">https://digitalcloud.training/amazon-elasticache/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/Strategies.html",
      "https://digitalcloud.training/amazon-elasticache/"
    ]
  },
  {
    "id": 49,
    "question": "<p>Twelve months ago, an organization requested a public certificate for their domain via AWS Certificate Manager (ACM). It was validated using DNS validation. What will ACM do prior to expiration? (Select TWO.)</p>",
    "corrects": [
      3,
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>If the certificate was issued by a third party, AWS ACM will send a request to the third party to verify the domain owner.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>If the certificate is being used by an AWS service and ACM-provided CNAME records are accessible via the public DNS, ACM will consider the domain name validated and send Health events or EventBridge events to notify the owner to renew the certificate.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>If the certificate is being used by an AWS service and ACM-provided CNAME records are accessible via the public DNS, ACM will consider the domain name validated and auto renew the certificate.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>If the domain is not validated, it will send Health events or EventBridge events to notify the domain owner prior to expiration.</p>",
        "correct": true
      },
      {
        "id": 5,
        "answer": "<p>If the certificate was validated through DNS validation with a valid CNAME record provided by ACM and is currently being used by an AWS service, it will use SNS to send notifications of pending expiration.</p>",
        "correct": false
      }
    ],
    "multiple": true,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>An AWS ACM certificate that was validated using DNS validation will automatically renew if the certificate is still being using by an AWS service 60 days prior to its expiration and has an ACM-provided CNAME that is accessible via public DNS. If the certificate is not being used or if the CNAME is not correct, ACM will not automatically validate the DNS and will send notifications starting at 45 days prior to the expiration date.</p><p><strong>CORRECT: </strong>“If the certificate is being used by an AWS service and ACM-provided CNAME records are accessible via the public DNS, ACM will consider the domain name validated and auto renew the certificate\" is the correct answer (as explained above.)</p><p><strong>CORRECT:</strong> \"If the domain is not validated, it will send Health events or EventBridge events to notify the domain owner prior to expiration\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"If the certificate is being used by an AWS service and ACM-provided CNAME records are accessible via the public DNS, ACM will consider the domain name validated and send Health events or EventBridge events to notify the owner to renew the certificate\" is incorrect. If criteria are met, DNS can be automatically validated and auto renewed without further action.</p><p><strong>INCORRECT:</strong> \"If the certificate was validated through DNS validation with a valid CNAME record provided by ACM and is currently being used by an AWS service, it will use SNS to send notifications of pending expiration\" is incorrect. If criteria are met, certificate is auto renewed with no further action or notifications required.</p><p><strong>INCORRECT:</strong> \"If the certificate was issued by a third party, AWS ACM will send a request to the third party to verify the domain owner\" is incorrect. The AWS ACM will not send a request. A new certificate will need to be created using AWS ACM or imported.</p><p><strong>References</strong>:</p><p><a href=\"https://docs.aws.amazon.com/acm/latest/userguide/dns-renewal-validation.html\">https://docs.aws.amazon.com/acm/latest/userguide/dns-renewal-validation.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-certificate-manager/\">https://digitalcloud.training/aws-certificate-manager/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/acm/latest/userguide/dns-renewal-validation.html",
      "https://digitalcloud.training/aws-certificate-manager/"
    ]
  },
  {
    "id": 50,
    "question": "<p>A Developer is deploying an application using Docker containers running on the Amazon Elastic Container Service (ECS). The Developer is testing application latency and wants to capture trace information between the microservices.</p><p>Which solution will meet these requirements?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Create a Docker image that runs the X-Ray daemon, upload it to a Docker image repository, and then deploy it to the Amazon ECS cluster.</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Install the AWS X-Ray daemon locally on an Amazon EC2 instance and instrument the Amazon ECS microservices using the X-Ray SDK.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Install the Amazon CloudWatch agent on the container image. Use the CloudWatch SDK to publish custom metrics from each of the microservices.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Install the AWS X-Ray daemon on each of the Amazon ECS instances.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Compute",
    "explanation": "<p>In Amazon ECS, create a Docker image that runs the X-Ray daemon, upload it to a Docker image repository, and then deploy it to your Amazon ECS cluster. You can use port mappings and network mode settings in your task definition file to allow your application to communicate with the daemon container.</p><p><strong>CORRECT: </strong>\"Create a Docker image that runs the X-Ray daemon, upload it to a Docker image repository, and then deploy it to the Amazon ECS cluster.\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Install the Amazon CloudWatch agent on the container image. Use the CloudWatch SDK to publish custom metrics from each of the microservices\" is incorrect. The CloudWatch agent does not capture trace information between Docker containers.</p><p><strong>INCORRECT:</strong> \"Install the AWS X-Ray daemon on each of the Amazon ECS instances\" is incorrect. The X-Ray daemon must be installed on the Docker containers, not the ECS hosts.</p><p><strong>INCORRECT:</strong> \"Install the AWS X-Ray daemon locally on an Amazon EC2 instance and instrument the Amazon ECS microservices using the X-Ray SDK\" is incorrect. You cannot trace Docker microservices from an Amazon EC2 instance.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ecs.html\">https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ecs.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-developer-tools/\">https://digitalcloud.training/aws-developer-tools/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ecs.html",
      "https://digitalcloud.training/aws-developer-tools/"
    ]
  },
  {
    "id": 51,
    "question": "<p>A start-up has launched a website using Route 53 for domain name, routing, and health checks. They failed to configure Amazon CloudWatch alarms with the health checks. How can the organization be made aware of any endpoint health issues?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>They can see the status of Route 53 health checks on the Shield dashboard.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>They can subscribe to SNS topics to receive notifications.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>They can see the status of Route 53 health checks on the Route 53 dashboard.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>They can create an alarm using CloudTrail and receive SNS notifications.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>Configuring CloudWatch alarms to send a SNS notification if there is an unhealthy endpoint is optional. AWS customers can also review the Route 53 dashboard to identify any health issues.</p><p><strong>CORRECT: </strong>\"They can see the status of Route 53 health checks on the Route 53 dashboard\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"They can see the status of Route 53 health checks on the Shield dashboard\" is incorrect. Route 53 health checks are not available on the Shield dashboard.</p><p><strong>INCORRECT:</strong> \"They can subscribe to SNS topics to receive notifications\" is incorrect. SNS topics can be used to send notifications but must be triggered by CloudWatch alarm first.</p><p><strong>INCORRECT:</strong> \"They can create an alarm using CloudTrail and receive SNS notifications\" is incorrect. CloudTrail is used to track API activity not for monitoring healthy resources.</p><p><strong>References</strong>:</p><p><a href=\"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/welcome-health-checks.html\">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/welcome-health-checks.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-route-53/\">https://digitalcloud.training/amazon-route-53/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/welcome-health-checks.html",
      "https://digitalcloud.training/amazon-route-53/"
    ]
  },
  {
    "id": 52,
    "question": "<p>A developer is creating a serverless web application that includes AWS Lambda functions and a REST API deployed using Amazon API Gateway. The developer maintains multiple branches of code. The developer wants to avoid updating the API gateway target endpoint when a new code push is performed.</p><p>What solution would allow the developer to update the Lambda code without needing to update the REST API configuration?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Create aliases and versions in AWS Lambda.</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Create multiple private API endpoints and use CNAMEs.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Create different tags for each Lambda function.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Create multiple stages and deployments.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Compute",
    "explanation": "<p>You can create one or more aliases for your Lambda function. A Lambda alias is like a pointer to a specific function version. Users can access the function version using the alias Amazon Resource Name (ARN). You can then release new versions of your code without needing to change the alias that applications use to invoke the function.</p><p>In this case the REST API could be configured with aliases for the functions. The developer could also use different stages with different endpoints using the aliases. This would enable calling different versions of the application by changing the stage name in the REST API URL.</p><p><strong>CORRECT: </strong>\"Create aliases and versions in AWS Lambda\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Create multiple stages and deployments\" is incorrect.</p><p>Stages and stage variables could be used to reference different functions or aliases. But if only stages and deployments are used (and not a Lambda alias) then the REST API would need to have the endpoint updated every time a new function version is released.</p><p><strong>INCORRECT:</strong> \"Create different tags for each Lambda function\" is incorrect.</p><p>Tags cannot be used to define the Lambda endpoints in the REST API.</p><p><strong>INCORRECT:</strong> \"Create multiple private API endpoints and use CNAMEs\" is incorrect.</p><p>There is no value here in creating multiple private API endpoints as that would be completely different APIs.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html\">https://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-lambda/\">https://digitalcloud.training/aws-lambda/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/lambda/latest/dg/configuration-aliases.html",
      "https://digitalcloud.training/aws-lambda/"
    ]
  },
  {
    "id": 53,
    "question": "<p>A company has an application that provides access to objects in Amazon S3 based on the type of user. The user types are registered user and guest user. The company has 30,000 users. Information is read from an S3 bucket depending on the user type.</p><p>Which approaches are recommended to provide access to both user types MOST efficiently? (Select TWO.)</p>",
    "corrects": [
      1,
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use Amazon Cognito to provide access using authenticated and unauthenticated roles.</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>Create a new IAM user for each user and grant access to the S3 objects.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use S3 bucket policies to restrict read access to specific IAM users.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Use the AWS IAM service and let the application assume different roles depending on the type of user.</p>",
        "correct": true
      },
      {
        "id": 5,
        "answer": "<p>Store separate access keys in the application code for registered users and guest users to provide access to the objects.</p>",
        "correct": false
      }
    ],
    "multiple": true,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>Amazon Cognito can be used with identity pools. A Cognito identity pool supports both authenticated and unauthenticated identities. Authenticated identities belong to users who are authenticated by any supported identity provider. Unauthenticated identities typically belong to guest users.</p><p>The most secure way of using the IAM service for this solution would be to use separate roles. IAM roles can be securely assumed based on the type of user. Each role can be configured with different permission sets as applicable to registered and guest users.</p><p><strong>CORRECT: </strong>\"Use Amazon Cognito to provide access using authenticated and unauthenticated roles\" is a correct answer (as explained above.)</p><p><strong>CORRECT: </strong>\"Use the AWS IAM service and let the application assume different roles depending on the type of user\" is also a correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Store separate access keys in the application code for registered users and guest users to provide access to the objects\" is incorrect.</p><p>This is highly insecure. You should avoid embedding access keys in application code and use IAM roles instead.</p><p><strong>INCORRECT:</strong> \"Create a new IAM user for each user and grant access to the S3 objects\" is incorrect.</p><p>This would be a lot of users and is an inefficient solution.</p><p><strong>INCORRECT:</strong> \"Use S3 bucket policies to restrict read access to specific IAM users\" is incorrect.</p><p>This would also be highly complex with so many users and would need constant updating when users need to be added or removed.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/cognito/latest/developerguide/identity-pools.html\">https://docs.aws.amazon.com/cognito/latest/developerguide/identity-pools.html</a></p><p><a href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html\">https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-iam/\">https://digitalcloud.training/aws-iam/</a></p><p><a href=\"https://digitalcloud.training/amazon-cognito/\">https://digitalcloud.training/amazon-cognito/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/cognito/latest/developerguide/identity-pools.html",
      "https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html",
      "https://digitalcloud.training/aws-iam/",
      "https://digitalcloud.training/amazon-cognito/"
    ]
  },
  {
    "id": 54,
    "question": "<p>A start-up organization imported their X.509 certificate from another issuer into AWS Certificate Manager (ACM) approximately 11 months ago. What needs to be done to ensure that visitors will continue to have secure access to the website? (Select TWO.)</p>",
    "corrects": [
      1,
      5
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>A new certificate will need to be imported into ACM.</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>A new certificate will automatically be created prior to the certificate expiring at 12 months.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>A new certificate will automatically be created prior to the certificate expiring at 13 months.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>A new certificate will be automatically imported into ACM.</p>",
        "correct": false
      },
      {
        "id": 5,
        "answer": "<p>A new certificate will need to be requested from ACM.</p>",
        "correct": true
      }
    ],
    "multiple": true,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>AWS ACM issued certificates are valid for 13 months. They are also renewed automatically. Imported certificates are not automatically renewed and would need to be imported once created from the third party.</p><p><strong>CORRECT: </strong>\"A new certificate will need to be requested from ACM\" is the correct answer (as explained above.)</p><p><strong>CORRECT: </strong>\"A new certificate will need to be imported into ACM” is also a correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"A new certificate will automatically be created prior to the certificate expiring at 12 months\" is incorrect. Imported certificates are not automatically renewed by AWS ACM.</p><p><strong>INCORRECT:</strong> \"A new certificate will automatically be created prior to the certificate expiring at 13 months\" is incorrect. Imported certificates are not automatically renewed by AWS ACM.</p><p><strong>INCORRECT:</strong> \"A new certificate will be automatically imported into ACM\" is incorrect. A new certificate issued by a third-party can be imported but it is not automatically done.</p><p><strong>References</strong>:</p><p><a href=\"https://docs.aws.amazon.com/acm/latest/userguide/managed-renewal.html\">https://docs.aws.amazon.com/acm/latest/userguide/managed-renewal.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-certificate-manager/\">https://digitalcloud.training/aws-certificate-manager/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/acm/latest/userguide/managed-renewal.html",
      "https://digitalcloud.training/aws-certificate-manager/"
    ]
  },
  {
    "id": 55,
    "question": "<p>A Developer is building a WebSocket API using Amazon API Gateway. The payload sent to this API is JSON that includes an action key which can have multiple values. The Developer must integrate with different routes based on the value of the action key of the incoming JSON payload.</p><p>How can the Developer accomplish this task with the LEAST amount of configuration?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Create a separate stage for each possible value of the action key.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Set the value of the route selection expression to $request.body.action.</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Set the value of the route selection expression to $default.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Create a mapping template to map the action key to an integration request.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>In your WebSocket API, incoming JSON messages are directed to backend integrations based on routes that you configure. (Non-JSON messages are directed to a $default route that you configure.)</p><p>A <em>route</em> includes a <em>route key</em>, which is the value that is expected once a <em>route selection expression</em> is evaluated. The routeSelectionExpression is an attribute defined at the API level. It specifies a JSON property that is expected to be present in the message payload.</p><p>For example, if your JSON messages contain an action property and you want to perform different actions based on this property, your route selection expression might be ${request.body.action}. Your routing table would specify which action to perform by matching the value of the action property against the custom route key values that you have defined in the table.</p><p><strong>CORRECT: </strong>\"Set the value of the route selection expression to $request.body.action\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Create a separate stage for each possible value of the action key\" is incorrect. There is no need to create separate stages, the action key can be used for routing as described above.</p><p><strong>INCORRECT:</strong> \"Create a mapping template to map the action key to an integration request\" is incorrect. Mapping templates are not used for routing to different integrations, they are used for transforming data.</p><p><strong>INCORRECT:</strong> \"Set the value of the route selection expression to $default\" is incorrect. The $default route is used for routing non-JSON messages.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/websocket-api-develop-routes.html\">https://docs.aws.amazon.com/apigateway/latest/Developerguide/websocket-api-develop-routes.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-api-gateway/\">https://digitalcloud.training/amazon-api-gateway/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/apigateway/latest/developerguide/websocket-api-develop-routes.html",
      "https://digitalcloud.training/amazon-api-gateway/"
    ]
  },
  {
    "id": 56,
    "question": "<p>A Developer is attempting to call the Amazon CloudWatch API and is receiving <code>HTTP 400: ThrottlingException</code> errors intermittently. When a call fails, no data is retrieved.</p><p>What best practice should the Developer first attempt to resolve this issue?</p>",
    "corrects": [
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Use the AWS CLI to get the metrics</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Analyze the applications and remove the API call</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Contact AWS Support for a limit increase</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Retry the call with exponential backoff</p>",
        "correct": true
      }
    ],
    "multiple": false,
    "domain": "AWS Management & Governance",
    "explanation": "<p>Occasionally ,you may receive the 400 ThrottlingException error for PutMetricData API calls in Amazon CloudWatch with a detailed response similar the following:</p><p><img src=\"https://img-c.udemycdn.com/redactor/raw/2020-04-20_09-16-39-a9b45a4e63ae15367e7fb66e598d68e4.jpg\" style=\"display: none;\"><span class=\"ud-component--base-components--open-full-size-image\"></span></p><div class=\"open-full-size-image--wrapper--R4gIm\" data-purpose=\"open-full-size-image\"><img src=\"https://img-c.udemycdn.com/redactor/raw/2020-04-20_09-16-39-a9b45a4e63ae15367e7fb66e598d68e4.jpg\" alt=\"\" loading=\"eager\"><button type=\"button\" class=\"ud-btn ud-btn-medium ud-btn-link ud-heading-sm open-full-size-image--backdrop--Zor3j\"><svg aria-label=\"Larger image\" role=\"img\" focusable=\"false\" class=\"ud-icon ud-icon-large ud-icon-color-neutral\"><use xlink:href=\"#icon-search\"></use></svg></button></div><p></p><p>CloudWatch requests are throttled for each Amazon Web Services (AWS) account on a per-Region basis to help service performance. For current PutMetricData API request limits, see CloudWatch Limits.</p><p>All calls to the PutMetricData API in an AWS Region count towards the maximum allowed request rate. This number includes calls from any custom or third-party application, such as calls from the CloudWatch Agent, the AWS Command Line Interface (AWS CLI), or the AWS Management Console.</p><p><strong>Resolutions: </strong>It's a best practice to use the following methods to reduce your call rate and avoid API throttling:</p><p>- Distribute your API calls evenly over time rather than making several API calls in a short time span. If you require data to be available with a one-minute resolution, you have an entire minute to emit that metric. Use jitter (randomized delay) to send data points at various times.</p><p>- Combine as many metrics as possible into a single API call. For example, a single PutMetricData call can include 20 metrics and 150 data points. You can also use pre-aggregated data sets, such as StatisticSet, to publish aggregated data points, thus reducing the number of PutMetricData calls per second.</p><p>- Retry your call with exponential backoff and jitter.</p><p>Following attempting the above resolutions AWS suggest the following: “If you still require a higher limit, you can <a href=\"https://console.aws.amazon.com/support/home#/case/create?issueType=service-limit-increase&amp;limitType=service-code-amazon-cloudwatch\">request a limit increase</a>. Increasing the rate limit can have a high financial impact on your AWS bill.”</p><p>Therefore, the first thing the Developer should do, from the list of options presented, is to retry the call with exponential backoff.</p><p><strong>CORRECT: </strong>\"Retry the call with exponential backoff\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Contact AWS Support for a limit increase\" is incorrect. As mentioned above, there are other resolutions the Developer should attempt before contacting support to raise the limit.</p><p><strong>INCORRECT:</strong> \"Use the AWS CLI to get the metrics\" is incorrect as this will still make the same API calls.</p><p><strong>INCORRECT:</strong> \"Analyze the applications and remove the API call\" is incorrect as this is not a good resolution to the issue as this may mean that important monitoring and logging data is not recorded for the application.</p><p><strong>References:</strong></p><p><a href=\"https://aws.amazon.com/premiumsupport/knowledge-center/cloudwatch-400-error-throttling/\">https://aws.amazon.com/premiumsupport/knowledge-center/cloudwatch-400-error-throttling/</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-cloudwatch/\">https://digitalcloud.training/amazon-cloudwatch/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://console.aws.amazon.com/support/home#/case/create?issueType=service-limit-increase&amp;limitType=service-code-amazon-cloudwatch",
      "https://aws.amazon.com/premiumsupport/knowledge-center/cloudwatch-400-error-throttling/",
      "https://digitalcloud.training/amazon-cloudwatch/"
    ]
  },
  {
    "id": 57,
    "question": "<p>In an organization, AWS CloudFormation templates are used to deploy all Amazon RDS DB instances as part of AWS CodePipeline CI/CD automation. As part of the deployment process, the main password for the DB instance needs to be auto generated.</p><p>What approach can be taken to fulfill these prerequisites with the minimum possible development effort?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Utilize AWS::EC2::KeyPair to generate a secure string and assign it as the password for the DB instance.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Write custom AWS Lambda function code that, when triggered, creates an encrypted string, and uses it as the password for the DB instance.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Use AWS Secrets Manager via the AWS SDK to generate a secure string. Use a dynamic reference to create the DB instance with the secret value.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Use AWS KMS to generate a random encryption key, then use this key as the password for the DB instance.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>This answer is correct because it leverages AWS Secrets Manager, a service designed specifically for secure storage and retrieval of secrets.</p><p>It does this without the added complexity and potential security concerns of using a custom Lambda function or CodeBuild action.</p><p>By using the secretsmanager dynamic reference in the CloudFormation template, you can retrieve the secret value directly, reducing the risk of exposure.</p><p><strong>CORRECT: </strong>\"Use AWS Secrets Manager via the AWS SDK to generate a secure string. Use a dynamic reference to create the DB instance with the secret value\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Use AWS KMS to generate a random encryption key, then use this key as the password for the DB instance\" is incorrect.</p><p>This is incorrect because AWS KMS is used for creating and managing cryptographic keys and controlling their use across a wide range of AWS services and in your applications, not for generating random strings.</p><p><strong>INCORRECT:</strong> \"Utilize AWS::EC2::KeyPair to generate a secure string and assign it as the password for the DB instance\" is incorrect.</p><p>This approach is incorrect as the AWS::EC2::KeyPair is used for SSH login information for EC2 instances, not for generating passwords for RDS DB instances.</p><p><strong>INCORRECT:</strong> \"Write custom AWS Lambda function code that, when triggered, creates an encrypted string, and uses it as the password for the DB instance\" is incorrect.</p><p>This approach introduces unnecessary complexity and development effort.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html\">https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-secrets-manager/\">https://digitalcloud.training/aws-secrets-manager/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html",
      "https://digitalcloud.training/aws-secrets-manager/"
    ]
  },
  {
    "id": 58,
    "question": "<p>A developer is using AWS AppConfig to deploy an application. The application's data needs to be encrypted when at rest. Which statement describes how this requirement is met?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Data is stored in S3 buckets unencrypted by default. The developer can use AWS Key Management Service (KMS) to apply encryption keys to the data at rest.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Data is automatically encrypted using AWS owned keys. This cannot be disabled. The developer can add an additional layer of encryption using customer managed keys.</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Data is automatically encrypted using AWS owned keys and AWS Key Management Service (KMS). The developer can disable this layer and instead add their own customer managed key.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Data is unencrypted by default. The developer can choose to use AWS managed keys or customer managed keys to encrypt the data.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Developer Tools",
    "explanation": "<p>AWS AppConfig will automatically encrypt data at rest using AWS owned keys and AWS Key Management Service (KMS). This layer cannot be disabled or altered by the customer. The customer can add a second layer of encryption protection that they can control and manage using customer managed keys.</p><p><strong>CORRECT</strong>: \"Data is automatically encrypted using AWS owned keys. This cannot be disabled. The developer can add an additional layer of encryption using customer managed keys\" is the correct answer (as explained above.)</p><p><strong>INCORRECT</strong>: \"Data is automatically encrypted using AWS owned keys and AWS Key Management Service (KMS). The developer can disable this layer and instead add their own customer managed key\" is incorrect. The default layer of encryption cannot be disabled. The developer can add a second layer of a customer managed key.</p><p><strong>INCORRECT</strong>: \"Data is stored in S3 buckets unencrypted by default. The developer can use AWS Key Management Service (KMS) to apply encryption keys to the data at rest\" is incorrect. Data is encrypted by default using AWS owned keys. The developer can use customer managed keys to add a second layer of encryption.</p><p><strong>INCORRECT</strong>: \"Data is unencrypted by default. The developer can choose to use AWS managed keys or customer managed keys to encrypt the data\" is incorrect. Data is encrypted by default using AWS managed keys and AWS Key Management Service (KMS). A second layer can be added using customer managed keys.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/appconfig/latest/userguide/appconfig-security.html\">https://docs.aws.amazon.com/appconfig/latest/userguide/appconfig-security.html</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/appconfig/latest/userguide/appconfig-security.html"
    ]
  },
  {
    "id": 59,
    "question": "<p>A company maintains a REST API service using Amazon API Gateway with native API key validation. The company recently launched a new registration page, which allows users to sign up for the service. The registration page creates a new API key using CreateApiKey and sends the new key to the user. When the user attempts to call the API using this key, the user receives a 403 Forbidden error. Existing users are unaffected and can still call the API.</p><p>What code updates will grant these new users’ access to the API?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>The <code>updateAuthorizer</code> method must be called to update the API’s authorizer to include the newly created API key</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>The <code>createUsagePlanKey </code>method must be called to associate the newly created API key with the correct usage plan</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>The <code>createDeployment</code> method must be called so the API can be redeployed to include the newly created API key</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>The <code>importApiKeys</code> method must be called to import all newly created API keys into the current stage of the API</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Networking & Content Delivery",
    "explanation": "<p>A <em>usage plan</em> specifies who can access one or more deployed API stages and methods—and also how much and how fast they can access them. The plan uses API keys to identify API clients and meters access to the associated API stages for each key. It also lets you configure throttling limits and quota limits that are enforced on individual client API keys.</p><p><img src=\"https://img-c.udemycdn.com/redactor/raw/2020-04-21_06-18-45-d98c869175c80055460abda8f9de14ff.png\" style=\"display: none;\"><span class=\"ud-component--base-components--open-full-size-image\"></span></p><div class=\"open-full-size-image--wrapper--R4gIm\" data-purpose=\"open-full-size-image\"><img src=\"https://img-c.udemycdn.com/redactor/raw/2020-04-21_06-18-45-d98c869175c80055460abda8f9de14ff.png\" alt=\"\" loading=\"eager\"><button type=\"button\" class=\"ud-btn ud-btn-medium ud-btn-link ud-heading-sm open-full-size-image--backdrop--Zor3j\"><svg aria-label=\"Larger image\" role=\"img\" focusable=\"false\" class=\"ud-icon ud-icon-large ud-icon-color-neutral\"><use xlink:href=\"#icon-search\"></use></svg></button></div><p></p><p><em>API keys</em> are alphanumeric string values that you distribute to application developer customers to grant access to your API. You can use API keys together with <a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-usage-plans.html\">usage plans</a> or <a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-use-lambda-authorizer.html\">Lambda authorizers</a> to control access to your APIs. API Gateway can generate API keys on your behalf, or you can import them from a <a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-key-file-format.html\">CSV file</a>. You can generate an API key in API Gateway, or import it into API Gateway from an external source.</p><p>To associate the newly created key with a usage plan the CreatUsagePlanKey API can be called. This creates a usage plan key for adding an existing API key to a usage plan.</p><p><strong>CORRECT: </strong>\"The createUsagePlanKey method must be called to associate the newly created API key with the correct usage plan\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"The createDeployment method must be called so the API can be redeployed to include the newly created API key\" is incorrect as you do not need to redeploy an API to a stage in order to associate an API key.</p><p><strong>INCORRECT:</strong> \"The updateAuthorizer method must be called to update the API’s authorizer to include the newly created API key\" is incorrect as this updates and authorizer resource, not an API key.</p><p><strong>INCORRECT:</strong> \"The importApiKeys method must be called to import all newly created API keys into the current stage of the API\" is incorrect as this imports API keys to API Gateway from an external source such as a CSV file which is not relevant to this scenario.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-usage-plans.html\">https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-usage-plans.html</a></p><p><a href=\"http://docs.amazonaws.cn/en_us/sdkfornet/v3/apidocs/items/APIGateway/MAPIGatewayCreateUsagePlanKeyCreateUsagePlanKeyRequest.html\">http://docs.amazonaws.cn/en_us/sdkfornet/v3/apidocs/items/APIGateway/MAPIGatewayCreateUsagePlanKeyCreateUsagePlanKeyRequest.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-api-gateway/\">https://digitalcloud.training/amazon-api-gateway/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-usage-plans.html",
      "https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-use-lambda-authorizer.html",
      "https://docs.aws.amazon.com/apigateway/latest/developerguide/api-key-file-format.html",
      "http://docs.amazonaws.cn/en_us/sdkfornet/v3/apidocs/items/APIGateway/MAPIGatewayCreateUsagePlanKeyCreateUsagePlanKeyRequest.html",
      "https://digitalcloud.training/amazon-api-gateway/"
    ]
  },
  {
    "id": 60,
    "question": "<p>A developer needs a long-term mountable storage solution for an Amazon Elastic Compute Cloud (EC2) instance using a compute optimized C6i instance type that meets heavily regulated compliance standards on data encryption for data at rest and in transit. What solution would provide this?</p>",
    "corrects": [
      2
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Attach an AWS Simple Storage Service (S3) bucket to the instance and enable encryption during creation.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Attach an Amazon Elastic Block Store (EBS) volume to the instance and enable encryption during creation.</p>",
        "correct": true
      },
      {
        "id": 3,
        "answer": "<p>Attach an Amazon Elastic Block Store (EBS) volume to the instance. Encryption is enabled automatically.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Attach an AWS Simple Storage Service (S3) bucket to the instance. Encryption is enabled automatically.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Storage",
    "explanation": "<p>Amazon EBS is permanent, mountable storage solution for Amazon EC2 instances. Amazon EBS volumes are not encrypted by default but can be encrypted for all current generation instance types and specific previous generation instance types. Amazon EBS volumes are not encrypted by default without additional configuration.</p><p><strong>CORRECT: </strong>\"Attach an Amazon Elastic Block Store (EBS) volume to the instance and enable encryption during creation\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Attach an Amazon Elastic Block Store (EBS) volume to the instance. Encryption is enabled automatically\" is incorrect.</p><p>Amazon EBS volumes can be configured to be encrypted upon creation or can be configured to encrypt new instances by default. AWS does not have Amazon EBS volumes encrypted by default.</p><p><strong>INCORRECT:</strong> \"Attach an AWS Simple Storage Service (S3) bucket to the instance and enable encryption during creation\" is incorrect.</p><p>Amazon S3 provides a block storage solution. It is not mountable to instances. In January 2023, AWS announced that new objects in AWS S3 would be encrypted by default.</p><p><strong>INCORRECT:</strong> Attach an AWS Simple Storage Service (S3) bucket to the instance. Encryption is enabled automatically\" is incorrect.</p><p>Amazon S3 provide a block storage solution. It is not mountable to instances.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html\">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-ebs/\">https://digitalcloud.training/amazon-ebs/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html",
      "https://digitalcloud.training/amazon-ebs/"
    ]
  },
  {
    "id": 61,
    "question": "<p>A company has deployed a new web application that uses Amazon Cognito for authentication. The company wants to allow sign-in from any source but wants to automatically block all sign-in attempts if the risk level is elevated.</p><p>Which Amazon Cognito feature will meet these requirements?</p>",
    "corrects": [
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Advanced security metrics.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Case sensitive user pools.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Multi-factor authentication (MFA).</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Adaptive authentication.</p>",
        "correct": true
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>With adaptive authentication, you can configure your user pool to block suspicious sign-ins or add second factor authentication in response to an increased risk level.</p><p>For each sign-in attempt, Amazon Cognito generates a risk score for how likely the sign-in request is to be from a compromised source. This risk score is based on many factors, including whether it detects a new device, user location, or IP address.</p><p><strong>For each risk level, you can choose from the following options:</strong></p><p> •&nbsp; Allow - Users can sign in without an additional factor.</p><p> •&nbsp; Optional MFA - Users who have a second factor configured must complete a second factor challenge to sign in.</p><p> •&nbsp; Require MFA - Users who have a second factor configured must complete a second factor challenge to sign in. Amazon Cognito blocks sign-in for users who don't have a second factor configured.</p><p> •&nbsp; Block - Amazon Cognito blocks all sign-in attempts at the designated risk level.</p><p>In this case the company should use adaptive authentication and configure Cognito to block sign-in attempts at the specific risk level they feel is appropriate.</p><p><strong>CORRECT: </strong>\"Adaptive authentication\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Advanced security metrics\" is incorrect.</p><p>Amazon Cognito publishes sign-in attempts, their risk levels, and failed challenges to Amazon CloudWatch. These are known as advanced security metrics. This information is useful for analysis, but adaptive authentication is required to automatically block sign-in attempts.</p><p><strong>INCORRECT:</strong> \"Multi-factor authentication (MFA)\" is incorrect.</p><p>This is not a method of blocking. In this case adaptive authentication with a block response should be configured.</p><p><strong>INCORRECT:</strong> \"Case sensitive user pools\" is incorrect.</p><p>This has nothing to do with responding to security threats. This is a configuration that determines whether Cognito considers the case of email addresses and usernames.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pool-settings-adaptive-authentication.html\">https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pool-settings-adaptive-authentication.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-cognito/\">https://digitalcloud.training/amazon-cognito/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pool-settings-adaptive-authentication.html",
      "https://digitalcloud.training/amazon-cognito/"
    ]
  },
  {
    "id": 62,
    "question": "<p>A Developer needs to be notified by email for all new object creation events in a specific Amazon S3 bucket. Amazon SNS will be used for sending the messages. How can the Developer enable these notifications?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Create an event notification for all <code>s3:ObjectRestore:Post</code> API calls</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Create an event notification for all <code>s3:ObjectCreated:Put</code> API calls</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Create an event notification for all <code>s3:ObjectCreated:*</code> API calls</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Create an event notification for all <code>s3:ObjectRemoved:Delete</code> API calls</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Storage",
    "explanation": "<p>The Amazon S3 notification feature enables you to receive notifications when certain events happen in your bucket. To enable notifications, you must first add a notification configuration that identifies the events you want Amazon S3 to publish and the destinations where you want Amazon S3 to send the notifications. You store this configuration in the <em>notification</em> subresource that is associated with a bucket.</p><p>Currently, Amazon S3 can publish notifications for the following events:</p><p><strong>New object created events</strong> — Amazon S3 supports multiple APIs to create objects. You can request notification when only a specific API is used (for example, s3:ObjectCreated:Put), or you can use a wildcard (for example, s3:ObjectCreated:*) to request notification when an object is created regardless of the API used.</p><p><strong>Object removal events</strong> — Amazon S3 supports deletes of versioned and unversioned objects. For information about object versioning, see <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html\">Object Versioning</a> and <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html\">Using Versioning</a>.</p><p><strong>Restore object events </strong>— Amazon S3 supports the restoration of objects archived to the S3 Glacier storage class. You request to be notified of object restoration completion by using s3:ObjectRestore:Completed. You use s3:ObjectRestore:Post to request notification of the initiation of a restore.</p><p><strong>Reduced Redundancy Storage (RRS) object lost events</strong> — Amazon S3 sends a notification message when it detects that an object of the RRS storage class has been lost.</p><p><strong>Replication events</strong> — Amazon S3 sends event notifications for replication configurations that have S3 Replication Time Control (S3 RTC) enabled. It sends these notifications when an object fails replication, when an object exceeds the 15-minute threshold, when an object is replicated after the 15-minute threshold, and when an object is no longer tracked by replication metrics. It publishes a second event when that object replicates to the destination Region.</p><p>Therefore, the Developer should create an event notification for all s3:ObjectCreated:* API calls as this will capture all new object creation events.</p><p><strong>CORRECT: </strong>\"Create an event notification for all <code>s3:ObjectCreated:*</code> API calls\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"Create an event notification for all <code>s3:ObjectCreated:Put</code> API calls\" is incorrect as this will not capture all new object creation events (e.g. POST or COPY). The wildcard should be used instead.</p><p><strong>INCORRECT:</strong> \"Create an event notification for all <code>s3:ObjectRemoved:Delete</code> API calls\" is incorrect as this is used for object deletions.</p><p><strong>INCORRECT:</strong> \"Create an event notification for all <code>s3:ObjectRestore:Post</code> API calls\" is incorrect as this is used for restore events from Amazon S3 Glacier archives.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html\">https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html</a></p><p><a href=\"https://aws.amazon.com/sns/faqs/\">https://aws.amazon.com/sns/faqs/</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/amazon-s3-and-glacier/\">https://digitalcloud.training/amazon-s3-and-glacier/</a></p><p><a href=\"https://digitalcloud.training/aws-application-integration-services/\">https://digitalcloud.training/aws-application-integration-services/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html",
      "https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html",
      "https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html",
      "https://aws.amazon.com/sns/faqs/",
      "https://digitalcloud.training/amazon-s3-and-glacier/",
      "https://digitalcloud.training/aws-application-integration-services/"
    ]
  },
  {
    "id": 63,
    "question": "<p>A new AWS Lambda function processes data and sends it to another service. The data is around 1 MB in size. A developer has been asked to update the function so it encrypts the data before sending it on to the other service.</p><p>Which API call is required to perform the encryption?</p>",
    "corrects": [
      3
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Pass the data directly to AWS KMS and issue the Encrypt API for encryption.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Issue the AWS KMS GenerateDataKeyWithoutPlainText API to return an encryption key.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Issue the AWS KMS GenerateDataKey API to return an encryption key.</p>",
        "correct": true
      },
      {
        "id": 4,
        "answer": "<p>Pass the data directly to AWS KMS and issue the ReEncrypt API for encryption.</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>To create a data key, call the GenerateDataKey operation. AWS KMS generates the data key. Then it encrypts a copy of the data key under a symmetric encryption KMS key that you specify. The operation returns a plaintext copy of the data key and the copy of the data key encrypted under the KMS key. The following image shows this operation.</p><img src=\"https://img-c.udemycdn.com/redactor/raw/test_question_description/2022-04-30_07-04-37-8dfdaca6937b17733985dbbd7ae4d9f2.jpg\" style=\"display: none;\"><span class=\"ud-component--base-components--open-full-size-image\"><div class=\"open-full-size-image--wrapper--R4gIm\" data-purpose=\"open-full-size-image\"><img src=\"https://img-c.udemycdn.com/redactor/raw/test_question_description/2022-04-30_07-04-37-8dfdaca6937b17733985dbbd7ae4d9f2.jpg\" alt=\"\" loading=\"eager\"><button type=\"button\" class=\"ud-btn ud-btn-medium ud-btn-link ud-heading-sm open-full-size-image--backdrop--Zor3j\"><svg aria-label=\"Larger image\" role=\"img\" focusable=\"false\" class=\"ud-icon ud-icon-large ud-icon-color-neutral\"><use xlink:href=\"#icon-search\"></use></svg></button></div></span><p>AWS KMS cannot use a data key to encrypt data. But you can use the data key outside of AWS KMS, such as by using OpenSSL or a cryptographic library like the AWS Encryption SDK.</p><p>After using the plaintext data key to encrypt data, remove it from memory as soon as possible. You can safely store the encrypted data key with the encrypted data, so it is available to decrypt the data.</p><img src=\"https://img-c.udemycdn.com/redactor/raw/test_question_description/2022-04-30_07-04-38-91457dce5546a2f8371cda0931b9552d.jpg\" style=\"display: none;\"><span class=\"ud-component--base-components--open-full-size-image\"><div class=\"open-full-size-image--wrapper--R4gIm\" data-purpose=\"open-full-size-image\"><img src=\"https://img-c.udemycdn.com/redactor/raw/test_question_description/2022-04-30_07-04-38-91457dce5546a2f8371cda0931b9552d.jpg\" alt=\"\" loading=\"eager\"><button type=\"button\" class=\"ud-btn ud-btn-medium ud-btn-link ud-heading-sm open-full-size-image--backdrop--Zor3j\"><svg aria-label=\"Larger image\" role=\"img\" focusable=\"false\" class=\"ud-icon ud-icon-large ud-icon-color-neutral\"><use xlink:href=\"#icon-search\"></use></svg></button></div></span><p>In this case, the Lambda function can use the encryption keys generated to encrypt the data before sending it to the other service. The GenerateDataKey API is the correct API action to use.</p><p><strong>CORRECT: </strong>\"Issue the AWS KMS GenerateDataKey API to return an encryption key\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Issue the AWS KMS GenerateDataKeyWithoutPlainText API to return an encryption key\" is incorrect.</p><p>This API action returns only an encrypted data key. When you need to use the data key, ask AWS KMS to decrypt it. The correct API for directly encrypting larger amounts of data is the GenerateDataKey API.</p><p><strong>INCORRECT:</strong> \"Pass the data directly to AWS KMS and issue the Encrypt API for encryption\" is incorrect.</p><p>AWS KMS can only encrypt data up to 4096 bytes. Therefore, the data must be encrypted outside of KMS and a data key must be generated for this purpose.</p><p><strong>INCORRECT:</strong> \"Pass the data directly to AWS KMS and issue the ReEncrypt API for encryption\" is incorrect.</p><p>The reencrypt API decrypts data before reencrypting it within AWS KMS. In this case the data is not currently encrypted and the operations cannot take place within KMS as the data is larger than the KMS maximum of 4096 bytes.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/kms/latest/APIReference/API_GenerateDataKey.html\">https://docs.aws.amazon.com/kms/latest/APIReference/API_GenerateDataKey.html</a></p><p><a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#data-keys\">https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#data-keys</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-kms/\">https://digitalcloud.training/aws-kms/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/kms/latest/APIReference/API_GenerateDataKey.html",
      "https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#data-keys",
      "https://digitalcloud.training/aws-kms/"
    ]
  },
  {
    "id": 64,
    "question": "<p>A Development team would like to migrate their existing application code from a GitHub repository to AWS CodeCommit.</p><p>What needs to be created before they can migrate a cloned repository to CodeCommit over HTTPS?</p>",
    "corrects": [
      1
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>A set of credentials generated from IAM</p>",
        "correct": true
      },
      {
        "id": 2,
        "answer": "<p>A public and private SSH key file</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>A GitHub secure authentication token</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>An Amazon EC2 IAM role with CodeCommit permissions</p>",
        "correct": false
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>The simplest way to set up connections to AWS CodeCommit repositories is to configure Git credentials for CodeCommit in the IAM console, and then use those credentials for HTTPS connections.</p><p>You can also use these same credentials with any third-party tool or individual development environment (IDE) that supports HTTPS authentication using a static user name and password. For examples, see <a href=\"https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-ide.html\">For Connections from Development Tools</a>.</p><p><strong>CORRECT: </strong>\"A set of credentials generated from IAM\" is the correct answer.</p><p><strong>INCORRECT:</strong> \"A GitHub secure authentication token\" is incorrect as this is not how you authenticated to CodeCommit.</p><p><strong>INCORRECT:</strong> \"A public and private SSH key file\" is incorrect as that is required for accessing CodeCommit using SSH.</p><p><strong>INCORRECT:</strong> \"An Amazon EC2 IAM role with CodeCommit permissions\" is incorrect as that would be used to provide access to administer CodeCommit. However, the question is asking how to authenticate a Git client to CodeCommit using HTTPS.</p><p><strong>References:</strong></p><p><a href=\"https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-gc.html\">https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-gc.html</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-developer-tools/\">https://digitalcloud.training/aws-developer-tools/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-ide.html",
      "https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-gc.html",
      "https://digitalcloud.training/aws-developer-tools/"
    ]
  },
  {
    "id": 65,
    "question": "<p>A company has launched a web application on Amazon EC2 instances behind an Application Load Balancer (ALB). The connection between clients and the ALB should use the HTTPS protocol. A developer uses AWS Certificate Manager (ACM) to issue an X.509 certificate.</p><p>What steps must the developer take to secure the connection?</p>",
    "corrects": [
      4
    ],
    "answers": [
      {
        "id": 1,
        "answer": "<p>Export the root key of the X.509 certificate to an Amazon S3 bucket. Configure each EC2 instance to use the same X.509 certificate from the S3 bucket.</p>",
        "correct": false
      },
      {
        "id": 2,
        "answer": "<p>Configure each EC2 instance to use the X.509 certificate by using the AWS Management Console.</p>",
        "correct": false
      },
      {
        "id": 3,
        "answer": "<p>Export the root key of the X.509 certificate to an Amazon S3 bucket. Configure the ALB to use the X.509 certificate from the S3 bucket.</p>",
        "correct": false
      },
      {
        "id": 4,
        "answer": "<p>Configure the ALB to use the X.509 certificate by using the AWS Management Console.</p>",
        "correct": true
      }
    ],
    "multiple": false,
    "domain": "AWS Security, Identity, & Compliance",
    "explanation": "<p>To secure the connection between clients and the ALB the developer must simply attach the certificate to the ALB. This can be performed using the AWS Management Console. There is no need to add the certificate to each EC2 instance. If end-to-end encryption is required, self-signed certificates or certificates issued by a private CA can be used on the EC2 instances (not required by the solution requirements).</p><p><strong>CORRECT: </strong>\"Configure the ALB to use the X.509 certificate by using the AWS Management Console\" is the correct answer (as explained above.)</p><p><strong>INCORRECT:</strong> \"Configure each EC2 instance to use the X.509 certificate by using the AWS Management Console\" is incorrect. This is not required as explained above.</p><p><strong>INCORRECT:</strong> \"Export the root key of the X.509 certificate to an Amazon S3 bucket. Configure the ALB to use the X.509 certificate from the S3 bucket\" is incorrect. This is the wrong procedure, the certificate can simply be attached to the ALB.</p><p><strong>INCORRECT:</strong> \"Export the root key of the X.509 certificate to an Amazon S3 bucket. Configure each EC2 instance to use the same X.509 certificate from the S3 bucket\" is incorrect. As explained above, this is not required and is the wrong procedure.</p><p><strong>References:</strong></p><p><a href=\"https://aws.amazon.com/premiumsupport/knowledge-center/associate-acm-certificate-alb-nlb/\">https://aws.amazon.com/premiumsupport/knowledge-center/associate-acm-certificate-alb-nlb/</a></p><p><strong>Save time with our AWS cheat sheets:</strong></p><p><a href=\"https://digitalcloud.training/aws-certificate-manager/\">https://digitalcloud.training/aws-certificate-manager/</a></p>",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": [
      "https://aws.amazon.com/premiumsupport/knowledge-center/associate-acm-certificate-alb-nlb/",
      "https://digitalcloud.training/aws-certificate-manager/"
    ]
  }
]