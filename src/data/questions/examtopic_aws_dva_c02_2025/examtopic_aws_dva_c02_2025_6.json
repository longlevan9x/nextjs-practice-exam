[
  {
    "id": 326,
    "question": "A company runs a payment application on Amazon EC2 instances behind an Application Load Balance. The EC2 instances run in an Auto Scaling group across multiple Availability Zones. The application needs to retrieve application secrets during the application startup and export the secrets as environment variables. These secrets must be encrypted at rest and need to be rotated every month.<br><br>Which solution will meet these requirements with the LEAST development effort?",
    "answers": [
      {
        "id": 1,
        "answer": "Save the secrets in a text file and store the text file in Amazon S3. Provision a customer managed key. Use the key for secret encryption in Amazon S3. Read the contents of the text file and read the export as environment variables. Configure S3 Object Lambda to rotate the text file every month.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Save the secrets as strings in AWS Systems Manager Parameter Store and use the default AWS Key Management Service (AWS KMS) key. Configure an Amazon EC2 user data script to retrieve the secrets during the startup and export as environment variables. Configure an AWS Lambda function to rotate the secrets in Parameter Store every month.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Save the secrets as base64 encoded environment variables in the application properties. Retrieve the secrets during the application startup. Reference the secrets in the application code. Write a script to rotate the secrets saved as environment variables.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Store the secrets in AWS Secrets Manager. Provision a new customer master key. Use the key to encrypt the secrets. Enable automatic rotation. Configure an Amazon EC2 user data script to programmatically retrieve the secrets during the startup and export as environment variables.",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 327,
    "question": "A company is using Amazon API Gateway to invoke a new AWS Lambda function. The company has Lambda function versions in its PROD and DEV environments. In each environment, there is a Lambda function alias pointing to the corresponding Lambda function version. API Gateway has one stage that is configured to point at the PROD alias.<br><br>The company wants to configure API Gateway to enable the PROD and DEV Lambda function versions to be simultaneously and distinctly available.<br><br>Which solution will meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Enable a Lambda authorizer for the Lambda function alias in API Gateway. Republish PROD and create a new stage for DEV. Create API Gateway stage variables for the PROD and DEV stages. Point each stage variable to the PROD Lambda authorizer to the DEV Lambda authorizer.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Set up a gateway response in API Gateway for the Lambda function alias. Republish PROD and create a new stage for DEV. Create gateway responses in API Gateway for PROD and DEV Lambda aliases.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Use an environment variable for the Lambda function alias in API Gateway. Republish PROD and create a new stage for development. Create API gateway environment variables for PROD and DEV stages. Point each stage variable to the PROD Lambda function alias to the DEV Lambda function alias.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Use an API Gateway stage variable to configure the Lambda function alias. Republish PROD and create a new stage for development. Create API Gateway stage variables for PROD and DEV stages. Point each stage variable to the PROD Lambda function alias and to the DEV Lambda function alias.",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 328,
    "question": "A developer is working on an ecommerce platform that communicates with several third-party payment processing APIs. The third-party payment services do not provide a test environment.<br><br>The developer needs to validate the ecommerce platform's integration with the third-party payment processing APIs. The developer must test the API integration code without invoking the third-party payment processing APIs.<br><br>Which solution will meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Set up an Amazon API Gateway REST API with a gateway response configured for status code 200. Add response templates that contain sample responses captured from the real third-party API.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Set up an AWS AppSync GraphQL API with a data source configured for each third-party API. Specify an integration type of Mock. Configure integration responses by using sample responses captured from the real third-party API.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Create an AWS Lambda function for each third-party API. Embed responses captured from the real third-party API. Configure Amazon Route 53 Resolver with an inbound endpoint for each Lambda function's Amazon Resource Name (ARN).",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Set up an Amazon API Gateway REST API for each third-party API. Specify an integration request type of Mock. Configure integration responses by using sample responses captured from the real third-party API.",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 329,
    "question": "A developer is storing many objects in a single Amazon S3 bucket. The developer needs to optimize the S3 bucket for high request rates.<br><br>How should the developer store the objects to meet this requirement?",
    "answers": [
      {
        "id": 1,
        "answer": "Store the objects by using S3 Intelligent-Tiering.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Store the objects at the root of the S3 bucket.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Store the objects by using object key names distributed across multiple prefixes.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Store each object with an object tag named \"prefix\" that contains a unique value.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 330,
    "question": "A company deploys a new application to AWS. The company is streaming application logs to Amazon CloudWatch Logs. The company's development team must receive notification by email when the word \"ERROR\" appears in any log lines. A developer sets up an Amazon Simple Notification Service (Amazon SNS) topic and subscribes the development team to the topic.<br><br>What should the developer do next to meet the requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Select the appropriate log group. Create a CloudWatch metric filter with \"ERROR\" as the search term. Create an alarm on this metric that notifies the SNS topic when the metric is 1 or higher.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "In CloudWatch Logs Insights, select the appropriate log group. Create a metric query to search for the term \"ERROR\" in the logs. Create an alarm on this metric that notifies the SNS topic when the metric is 1 or higher.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Select the appropriate log group. Create an SNS subscription filter with \"ERROR\" as the filter pattern. Select the SNS topic as the destination.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Create a CloudWatch alarm that includes \"ERROR\" as a filter pattern, a log group dimension that defines the appropriate log group, and a destination that notifies the SNS topic.",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 331,
    "question": "A company uses Amazon Simple Queue Service (Amazon SQS) to decouple its microservices architecture. Some messages in an SQS queue contain sensitive information. A developer must implement a solution that encrypts all the data at rest.<br><br>Which solution will meet this requirement?",
    "answers": [
      {
        "id": 1,
        "answer": "Enable server-side encryption for the SQS queue by using an SQS managed encryption key (SSE-SQS).",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Use the aws:SecureTransport condition in the queue policy to ensure that only HTTPS (TLS) is used for all requests to the SQS queue.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Use AWS Certificate Manager (ACM) to generate an SSL/TLS certificate. Reference the certificate when messages are sent to the queue.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Set a message attribute in the SQS SendMessage request for messages that are sent to the queue. Set the Name to ENCRYPT. Set the Value to TRUE.",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 332,
    "question": "A company recently deployed a new serverless user portal. Users have reported that part of the portal is slow. The initial analysis found a single Amazon API Gateway endpoint that is responsible for the performance issues. The endpoint integrates with an AWS Lambda function. However, the Lambda function interacts with other APIs and AWS services.<br><br>How can a developer find the source of the increased response time by using operational best practices?",
    "answers": [
      {
        "id": 1,
        "answer": "Update the Lambda function by adding logging statements with high-precision timestamps before and after each external request. Deploy the updated Lambda function. After accumulating enough usage data, examine the Amazon CloudWatch logs for the Lambda function to determine the likely sources for the increased response time.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Instrument the Lambda function with the AWS X-Ray SDK. Add HTTP and HTTPS interceptors and SDK client handlers. Deploy the updated Lambda function. Turn on X-Ray tracing. After accumulating enough usage data, use the X-Ray service map to examine the average response times to determine the likely sources.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Review the Lambda function's Amazon CloudWatch metrics by using the metrics explorer. Apply anomaly detection to the Duration metric and the Throttles metric. Review the anomalies to determine the likely sources.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Use Amazon CloudWatch Synthetics to create a new canary. Turn on AWS X-Ray tracing on the canary. Configure the canary to scan the user portal. After accumulating enough usage data, use the CloudWatch Synthetics canary dashboard to view the metrics from the canary.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 333,
    "question": "A developer is building an event-driven application by using AWS Lambda and Amazon EventBridge. The Lambda function needs to push events to an EventBridge event bus. The developer uses an SDK to run the PutEvents EventBridge action and specifies no credentials in the code. After deploying the Lambda function, the developer notices that the function is failing and there are AccessDeniedException errors in the logs.<br><br>How should the developer resolve this issue?",
    "answers": [
      {
        "id": 1,
        "answer": "Configure a VPC peering connection between the Lambda function and EventBridge.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Modify their AWS credentials to include permissions for the PutEvents EventBridge action.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Modify the Lambda function execution role to include permissions for the PutEvents EventBridge action.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Add a resource-based policy to the Lambda function to include permissions for the PutEvents EventBridge action.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 334,
    "question": "A company's application has an AWS Lambda function that processes messages from IoT devices. The company wants to monitor the Lambda function to ensure that the Lambda function is meeting its required service level agreement (SLA).<br><br>A developer must implement a solution to determine the application's throughput in near real time. The throughput must be based on the number of messages that the Lambda function receives and processes in a given time period. The Lambda function performs initialization and post-processing steps that must not factor into the throughput measurement.<br><br>What should the developer do to meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Use the Lambda function's ConcurrentExecutions metric in Amazon CloudWatch to measure the throughput.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Modify the application to log the calculated throughput to Amazon CloudWatch Logs. Use Amazon EventBridge to invoke a separate Lambda function to process the logs on a schedule.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Modify the application to publish custom Amazon CloudWatch metrics when the Lambda function receives and processes each message. Use the metrics to calculate the throughput.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Use the Lambda function's Invocations metric and Duration metric to calculate the throughput in Amazon CloudWatch.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 335,
    "question": "A developer is using an AWS CodePipeline pipeline to provide continuous integration and continuous delivery (CI/CD) support for a Java application. The developer needs to update the pipeline to support the introduction of a new application dependency .jar file. The pipeline must start a build when a new version of the .jar file becomes available.<br><br>Which solution will meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Create an Amazon S3 bucket to store the dependency .jar file. Publish the dependency .jar file to the S3 bucket. Use an Amazon Simple Notification Service (Amazon SNS) notification to start a CodePipeline pipeline build.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Create an Amazon Elastic Container Registry (Amazon ECR) private repository. Publish the dependency .jar file to the repository. Use an ECR source action to start a CodePipeline pipeline build.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Create an Amazon Elastic Container Registry (Amazon ECR) private repository. Publish the dependency .jar file to the repository. Use an Amazon Simple Notification Service (Amazon SNS) notification to start a CodePipeline pipeline build.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Create an AWS CodeArtifact repository. Publish the dependency .jar file to the repository. Use an Amazon EventBridge rule to start a CodePipeline pipeline build.",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 336,
    "question": "A company with multiple branch locations has an analytics and reporting application. Each branch office pushes a sales report to a shared Amazon S3 bucket at a predefined time each day. The company has developed an AWS Lambda function that analyzes the reports from all branch offices in a single pass. The Lambda function stores the results in a database.<br><br>The company needs to start the analysis once each day at a specific time.<br><br>Which solution will meet these requirements MOST cost-effectively?",
    "answers": [
      {
        "id": 1,
        "answer": "Configure an S3 event notification to invoke the Lambda function when a branch office uploads a sales report.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Create an AWS Step Functions state machine that invokes the Lambda function once each day at the predefined time.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Configure the Lambda function to run continuously and to begin analysis only at the predefined time each day.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Create an Amazon EventBridge scheduled rule that invokes the Lambda function once each day at the predefined time.",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 337,
    "question": "A developer has an application that asynchronously invokes an AWS Lambda function. The developer wants to store messages that resulted in failed invocations of the Lambda function so that the application can retry the call later.<br><br>What should the developer do to accomplish this goal with the LEAST operational overhead?",
    "answers": [
      {
        "id": 1,
        "answer": "Set up Amazon CloudWatch Logs log groups to filter and store the messages in an Amazon S3 bucket. Import the messages in Lambda. Run the Lambda function again.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Configure Amazon EventBridge to send the messages to Amazon Simple Notification Service (Amazon SNS) to initiate the Lambda function again.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Implement a dead-letter queue for discarded messages. Set the dead-letter queue as an event source for the Lambda function.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Send Amazon EventBridge events to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the Lambda function to pull messages from the SQS queue. Run the Lambda function again.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 338,
    "question": "A company is using AWS CloudFormation templates to deploy AWS resources. The company needs to update one of its AWS CloudFormation stacks.<br><br>What can the company do to find out how the changes will impact the resources that are running?",
    "answers": [
      {
        "id": 1,
        "answer": "Investigate the change sets.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Investigate the stack policies.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Investigate the Metadata section.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Investigate the Resources section.",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 339,
    "question": "A company stores all personally identifiable information (PII) in an Amazon DynamoDB table named PII in Account A. Developers are working on an application that is running on Amazon EC2 instances in Account B. The application in Account B requires access to the PII table.<br><br>An administrator in Account A creates an IAM role named AccessPII that has permission to access the PII table. The administrator also creates a trust policy that specifies Account B as a principal that can assume the role.<br><br>Which combination of steps should the developers take in Account B to allow their application to access the PII table? (Choose two.)",
    "answers": [
      {
        "id": 1,
        "answer": "Allow the EC2 IAM role the permission to assume the AccessPII role.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Allow the EC2 IAM role the permission to access the PII table.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Include the AWS API in the application code logic to obtain temporary credentials from the EC2 IAM role to access the PII table.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Include the AssumeRole API operation in the application code logic to obtain temporary credentials to access the PII table.",
        "correct": true
      },
      {
        "id": 5,
        "answer": "Include the GetSessionToken API operation in the application code logic to obtain temporary credentials to access the PII table.",
        "correct": false
      }
    ],
    "corrects": [
      1,
      4
    ],
    "multiple": true,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 340,
    "question": "A gaming website gives users the ability to trade game items with each other on the platform. The platform requires both users' records to be updated and persisted in one transaction. If any update fails, the transaction must roll back.<br><br>Which AWS solutions can provide the transactional capability that is required for this feature? (Choose two.)",
    "answers": [
      {
        "id": 1,
        "answer": "Amazon DynamoDB with operations made with the ConsistentRead parameter set to true",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Amazon ElastiCache for Memcached with operations made within a transaction block",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Amazon DynamoDB with reads and writes made by using Transact* operations",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Amazon Aurora MySQL with operations made within a transaction block",
        "correct": true
      },
      {
        "id": 5,
        "answer": "Amazon Athena with operations made within a transaction block",
        "correct": false
      }
    ],
    "corrects": [
      3,
      4
    ],
    "multiple": true,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 341,
    "question": "A developer is deploying an application in the AWS Cloud by using AWS CloudFormation. The application will connect to an existing Amazon RDS database. The hostname of the RDS database is stored in AWS Systems Manager Parameter Store as a plaintext value. The developer needs to incorporate the database hostname into the CloudFormation template to initialize the application when the stack is created.<br><br>How should the developer reference the parameter that contains the database hostname?",
    "answers": [
      {
        "id": 1,
        "answer": "Use the ssm dynamic reference.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Use the Ref intrinsic function.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Use the Fn::ImportValue intrinsic function.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Use the ssm-secure dynamic reference.",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 342,
    "question": "A company uses an AWS Lambda function to call a third-party service. The third-party service has a limit of requests each minute. If the number of requests exceeds the limit, the third-party service returns rate-limiting errors.<br><br>A developer needs to configure the Lambda function to avoid receiving rate limiting errors from the third-party service.<br><br>Which solution will meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Set the reserved concurrency on the Lambda function to match the number of concurrent requests that the third-party service allows.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Decrease the memory that is allocated to the Lambda function.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Set the provisioned concurrency on the Lambda function to match the number of concurrent requests that the third-party service allows.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Increase the timeout value that is specified on the Lambda function.",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 343,
    "question": "A developer is building a new containerized application by using AWS Copilot. The developer uses the AWS Copilot command line interface (CLI) to deploy the application during development. The developer committed the application code to a new AWS CodeCommit repository. The developer must create an automated deployment process before releasing the new application to production.<br><br>What should the developer do to meet these requirements in the MOST operationally efficient way?",
    "answers": [
      {
        "id": 1,
        "answer": "Create a buildspec file that invokes the AWS Copilot CLI commands to build and deploy the application. Use the AWS Copilot CLI to create an AWS CodePipeline that uses the CodeCommit repository in the source stage and AWS CodeBuild in the build stage.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Use the AWS Serverless Application Model (AWS SAM) CLI to bootstrap and initialize an AWS CodePipeline configuration. Use the CodeCommit repository as the source. Invoke the AWS Copilot CLI to build and deploy the application.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Use the AWS Copilot CLI to define the AWS Copilot pipeline and to deploy the AWS CodePipeline. Select CodeCommit as the source for the AWS CodePipeline.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Define an AWS CloudFormation template for an AWS CodePipeline with CodeCommit as the source. Configure the template as an AWS Copilot CLI add-on. Use the AWS Copilot CLI to deploy the application.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 344,
    "question": "A developer is creating a new application for a pet store. The application will manage customer rewards points. The developer will use Amazon DynamoDB to store the data for the application. The developer needs to optimize query performance and limit partition overload before actual performance analysis.<br><br>Which option should the developer use for a partition key to meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "A randomly generated universally unique identifier (UUID)",
        "correct": true
      },
      {
        "id": 2,
        "answer": "The customer's full name",
        "correct": false
      },
      {
        "id": 3,
        "answer": "The date when the customer signed up for the rewards program",
        "correct": false
      },
      {
        "id": 4,
        "answer": "The name of the customer's pet",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 345,
    "question": "A developer uses AWS IAM Identity Center (AWS Single Sign-On) to interact with the AWS CLI and AWS SDKs on a local workstation. API calls to AWS services were working when the SSO access was first configured. However, the developer is now receiving Access Denied errors. The developer has not changed any configuration files or scripts that were previously working on the workstation.<br><br>What is the MOST likely cause of the developer's access issue?",
    "answers": [
      {
        "id": 1,
        "answer": "The access permissions to the developer's AWS CLI binary file have changed.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "The permission set that is assumed by IAM Identity Center does not have the necessary permissions to complete the API call.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "The credentials from the IAM Identity Center federated role have expired.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "The developer is attempting to make API calls to the incorrect AWS account.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 346,
    "question": "A company is building a serverless application. The application uses an API key to authenticate with a third-party application. The company wants to store the external API key as a part of an AWS Lambda configuration. The company needs to have full control over the AWS Key Management Service (AWS KMS) keys that will encrypt the API key and should be visible only to authorized entities.<br><br>Which solution will meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Store the API key in AWS Systems Manager Parameter Store as a string parameter. Use the default AWS KMS key that AWS provides to encrypt the API key.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Store the API key in AWS Lambda environment variables. Create an AWS KMS customer managed key to encrypt the API key.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Store the API key in the code repository. Use an AWS managed key to encrypt the code repository.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Store the API key as an Amazon DynamoDB table record. Use an AWS managed key to encrypt the API key.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 347,
    "question": "A developer is writing an application to analyze the traffic to a fleet of Amazon EC2 instances. The EC2 instances run behind a public Application Load Balancer (ALB). An HTTP server runs on each of the EC2 instances, logging all requests to a log file.<br><br>The developer wants to capture the client public IP addresses. The developer analyzes the log files and notices only the IP address of the ALB.<br><br>What must the developer do to capture the client public IP addresses in the log file?",
    "answers": [
      {
        "id": 1,
        "answer": "Add a Host header to the HTTP server log configuration file.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Install the Amazon CloudWatch Logs agent on each EC2 instance. Configure the agent to write to the log file.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Install the AWS X-Ray daemon on each EC2 instance. Configure the daemon to write to the log file.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Add an X-Forwarded-For header to the HTTP server log configuration file.",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 348,
    "question": "A company is developing a serverless application by using AWS Lambda functions. One of the Lambda functions needs to access an Amazon RDS DB instance. The DB instance is in a private subnet inside a VPC.<br><br>The company creates a role that includes the necessary permissions to access the DB instance. The company then assigns the role to the Lambda function. A developer must take additional action to give the Lambda function access to the DB instance.<br><br>What should the developer do to meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Assign a public IP address to the DB instance. Modify the security group of the DB instance to allow inbound traffic from the IP address of the Lambda function.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Set up an AWS Direct Connect connection between the Lambda function and the DB instance.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Configure an Amazon CloudFront distribution to create a secure connection between the Lambda function and the DB instance.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Configure the Lambda function to connect to the private subnets in the VPC. Add security group rules to allow traffic to the DB instance from the Lambda function.",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 349,
    "question": "A developer needs temporary access to resources in a second account.<br><br>What is the MOST secure way to achieve this?",
    "answers": [
      {
        "id": 1,
        "answer": "Use the Amazon Cognito user pools to get short-lived credentials for the second account.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Create a dedicated IAM access key for the second account, and send it by mail.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Create a cross-account access role, and use sts:AssumeRole API to get short-lived credentials.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Establish trust, and add an SSH key for the second account to the IAM user.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 350,
    "question": "A company wants to migrate applications from its on-premises servers to AWS. As a first step, the company is modifying and migrating a non-critical application to a single Amazon EC2 instance. The application will store information in an Amazon S3 bucket. The company needs to follow security best practices when deploying the application on AWS.<br><br>Which approach should the company take to allow the application to interact with Amazon S3?",
    "answers": [
      {
        "id": 1,
        "answer": "Create an IAM role that has administrative access to AWS. Attach the role to the EC2 instance.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Create an IAM user. Attach the AdministratorAccess policy. Copy the generated access key and secret key. Within the application code, use the access key and secret key along with the AWS SDK to communicate with Amazon S3.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Create an IAM role that has the necessary access to Amazon S3. Attach the role to the EC2 instance.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Create an IAM user. Attach a policy that provides the necessary access to Amazon S3. Copy the generated access key and secret key. Within the application code, use the access key and secret key along with the AWS SDK to communicate with Amazon S3.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 351,
    "question": "A company has an internal website that contains sensitive data. The company wants to make the website public. The company must ensure that only employees who authenticate through the company's OpenID Connect (OIDC) identity provider (IdP) can access the website. A developer needs to implement authentication without editing the website.<br><br>Which combination of steps will meet these requirements? (Choose two.)",
    "answers": [
      {
        "id": 1,
        "answer": "Create a public Network Load Balancer.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Create a public Application Load Balancer.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Configure a listener for the load balancer that listens on HTTPS port 443. Add a default authenticate action providing the OIDC IdP configuration.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Configure a listener for the load balancer that listens on HTTP port 80. Add a default authenticate action providing the OIDC IdP configuration.",
        "correct": false
      },
      {
        "id": 5,
        "answer": "Configure a listener for the load balancer that listens on HTTPS port 443. Add a default AWS Lambda action providing an Amazon Resource Name (ARN) to a Lambda authentication function.",
        "correct": false
      }
    ],
    "corrects": [
      2,
      3
    ],
    "multiple": true,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 352,
    "question": "A developer is working on a web application that requires selective activation of specific features. The developer wants to keep the features hidden from end users until the features are ready for public access.<br><br>Which solution will meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Create a feature flag configuration profile in AWS AppSync. Store the feature flag values in the configuration profile. Activate and deactivate feature flags as needed.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Store prerelease data in an Amazon DynamoDB table. Enable Amazon DynamoDB Streams in the table. Toggle between hidden and visible states by using DynamoDB Streams.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Create a feature flag configuration profile in AWS AppConfig. Store the feature flag values in the configuration profile. Activate and deactivate feature flags as needed.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Store prerelease data in AWS Amplify DataStore. Toggle between hidden and visible states by using Amplify DataStore cloud synchronization.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 353,
    "question": "A developer at a company writes an AWS CloudFormation template. The template refers to subnets that were created by a separate AWS CloudFormation template that the company's network team wrote. When the developer attempts to launch the stack for the first time, the launch fails.<br><br>Which template coding mistakes could have caused this failure? (Choose two.)",
    "answers": [
      {
        "id": 1,
        "answer": "The developer's template does not use the Ref intrinsic function to refer to the subnets.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "The developer's template does not use the ImportValue intrinsic function to refer to the subnets.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "The Mappings section of the developer's template does not refer to the subnets.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "The network team's template does not export the subnets in the Outputs section.",
        "correct": true
      },
      {
        "id": 5,
        "answer": "The network team's template does not export the subnets in the Mappings section.",
        "correct": false
      }
    ],
    "corrects": [
      2,
      4
    ],
    "multiple": true,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 354,
    "question": "A developer is running an application on an Amazon EC2 instance. When the application tries to read an Amazon S3 bucket, the application fails. The developer notices that the associated IAM role is missing the S3 read permission. The developer needs to give the application the ability to read the S3 bucket.<br><br>Which solution will meet this requirement with the LEAST application disruption?",
    "answers": [
      {
        "id": 1,
        "answer": "Add the permission to the role. Terminate the existing EC2 instance. Launch a new EC2 instance.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Add the permission to the role so that the change will take effect automatically.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Add the permission to the role. Hibernate and restart the existing EC2 instance.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Add the permission to the S3 bucket. Restart the EC2 instance.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 355,
    "question": "A developer is writing a web application that is deployed on Amazon EC2 instances behind an internet-facing Application Load Balancer (ALB). The developer must add an Amazon CloudFront distribution in front of the ALB. The developer also must ensure that customer data from outside the VPC is encrypted in transit.<br><br>Which combination of CloudFront configuration settings should the developer use to meet these requirements? (Choose two.)",
    "answers": [
      {
        "id": 1,
        "answer": "Restrict viewer access by using signed URLs.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Set the Origin Protocol Policy setting to Match Viewer.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Enable field-level encryption.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Enable automatic object compression.",
        "correct": false
      },
      {
        "id": 5,
        "answer": "Set the Viewer Protocol Policy setting to Redirect HTTP to HTTPS.",
        "correct": true
      }
    ],
    "corrects": [
      2,
      5
    ],
    "multiple": true,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 356,
    "question": "A developer is implementing an AWS Lambda function that will be invoked when an object is uploaded to Amazon S3. The developer wants to test the Lambda function in a local development machine before publishing the function to a production AWS account.<br><br>Which solution will meet these requirements with the LEAST operational overhead?",
    "answers": [
      {
        "id": 1,
        "answer": "Upload an object to Amazon S3 by using the aws s3api put-object CLI command. Wait for the local Lambda invocation from the S3 event.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Create a sample JSON text file for a put object S3 event. Invoke the Lambda function locally. Use the aws lambda invoke CLI command with the JSON file and Lambda function name as arguments.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Use the sam local start-lambda CLI command to start Lambda. Use the sam local generate-event s3 put CLI command to create the Lambda test JSON file. Use the sam local invoke CLI command with the JSON file as the argument to invoke the Lambda function.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Create a JSON string for the put object S3 event. In the AWS Management Console, use the JSON string to create a test event for the local Lambda function. Perform the test.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 357,
    "question": "A developer is publishing critical log data to a log group in Amazon CloudWatch Logs. The log group was created 2 months ago. The developer must encrypt the log data by using an AWS Key Management Service (AWS KMS) key so that future data can be encrypted to comply with the company's security policy.<br><br>Which solution will meet this requirement with the LEAST effort?",
    "answers": [
      {
        "id": 1,
        "answer": "Use the AWS Encryption SDK for encryption and decryption of the data before writing to the log group.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Use the AWS KMS console to associate the KMS key with the log group.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Use the AWS CLI aws logs create-log-group command, and specify the key Amazon Resource Name (ARN).",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Use the AWS CLI aws logs associate-kms-key command, and specify the key Amazon Resource Name (ARN).",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 358,
    "question": "A developer is working on an app for a company that uses an Amazon DynamoDB table named Orders to store customer orders. The table uses OrderID as the partition key and there is no sort key. The table contains more than 100,000 records. The developer needs to add a functionality that will retrieve all Orders records that contain an OrderSource attribute with the MobileApp value.<br><br>Which solution will improve the user experience in the MOST efficient way?",
    "answers": [
      {
        "id": 1,
        "answer": "Perform a Scan operation on the Orders table. Provide a QueryFilter condition to filter to only the items where the OrderSource attribute is equal to the MobileApp value.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Create a local secondary index (LSI) with OrderSource as the partition key. Perform a Query operation by using MobileApp as the key.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Create a global secondary index (GSI) with OrderSource as the sort key. Perform a Query operation by using MobileApp as the key.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Create a global secondary index (GSI) with OrderSource as the partition key. Perform a Query operation by using MobileApp as the key.",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 359,
    "question": "A company has an application that uses an AWS Lambda function to process data. A developer must implement encryption in transit for all sensitive configuration data, such as API keys, that is stored in the application. The developer creates an AWS Key Management Service (AWS KMS) customer managed key.<br><br>What should the developer do next to meet the encryption requirement?",
    "answers": [
      {
        "id": 1,
        "answer": "Create parameters of the String type in AWS Systems Manager Parameter Store. For each parameter, specify the KMS key ID to encrypt the parameter in transit. Reference the GetParameter API call in the Lambda environment variables.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Create secrets in AWS Secrets Manager by using the customer managed KMS key. Create a new Lambda function and set up a Lambda layer. Configure the Lambda layer to retrieve the values from Secrets Manager.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Create objects in Amazon S3 for each sensitive data field. Specify the customer managed KMS key to encrypt the object. Configure the Lambda function to retrieve the objects from Amazon S3 during data processing.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Create encrypted Lambda environment variables. Specify the customer managed KMS key to encrypt the variables. Enable encryption helpers for encryption in transit. Grant permission to the Lambda function's execution role to access the KMS key.",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 360,
    "question": "A developer is building an ecommerce application. When there is a sale event, the application needs to concurrently call three third-party systems to record the sale. The developer wrote three AWS Lambda functions. There is one Lambda function for each third-party system, which contains complex integration logic.<br><br>These Lambda functions are all independent. The developer needs to design the application so each Lambda function will run regardless of others' success or failure.<br><br>Which solution will meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Publish the sale event from the application to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the three Lambda functions to poll the queue.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Publish the sale event from the application to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the three Lambda functions to be triggered by the SNS topic.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Publish the sale event from the application to an Application Load Balancer (ALB). Add the three Lambda functions as ALB targets.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Publish the sale event from the application to an AWS Step Functions state machine. Move the logic from the three Lambda functions into the Step Functions state machine.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 361,
    "question": "A developer is writing an application, which stores data in an Amazon DynamoDB table. The developer wants to query the DynamoDB table by using the partition key and a different sort key value. The developer needs the latest data with all recent write operations.<br><br>How should the developer write the DynamoDB query?",
    "answers": [
      {
        "id": 1,
        "answer": "Add a local secondary index (LSI) during table creation. Query the LSI by using eventually consistent reads.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Add a local secondary index (LSI) during table creation. Query the LSI by using strongly consistent reads.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Add a global secondary index (GSI) during table creation. Query the GSI by using eventually consistent reads.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Add a global secondary index (GSI) during table creation. Query the GSI by using strongly consistent reads.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 362,
    "question": "A developer manages an application that writes customer orders to an Amazon DynamoDB table. The orders use customer_id as the partition key, order_id as the sort key, and order_date as an attribute. A new access pattern requires accessing data by order_date and order_id. The developer needs to implement a new AWS Lambda function to support the new access pattern.<br><br>How should the developer support the new access pattern in the MOST operationally efficient way?",
    "answers": [
      {
        "id": 1,
        "answer": "Add a new local secondary index (LSI) to the DynamoDB table that specifies order_date as the partition key and order_id as the sort key. Write the new Lambda function to query the new LSI index.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Write the new Lambda function to scan the DynamoDB table. In the Lambda function, write a method to retrieve and combine results by order_date and order_id.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Add a new global secondary index (GSI) to the DynamoDB table that specifies order_date as the partition key and order_id as the sort key. Write the new Lambda function to query the new GSI index.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Enable DynamoDB Streams on the table. Choose the new and old images information to write to the DynamoDB stream. Write the new Lambda function to query the DynamoDB stream",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 363,
    "question": "A developer is creating a web application for a school that stores data in Amazon DynamoDB. The ExamScores table has the following attributes: student_id, subject_name, and top_score.<br><br>Each item in the ExamScores table is identified with student_id as the partition key and subject_name as the sort key. The web application needs to display the student _id for the top scores for each school subject. The developer needs to increase the speed of the queries to retrieve the student_id for the top scorer for each school subject.<br><br>Which solution will meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Create a local secondary index (LSI) with subject_name as the partition key and top_score as the sort key.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Create a local secondary index (LSI) with top_score as the partition key and student_id as the sort key.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Create a global secondary index (GSI) with subject_name as the partition key and top_score as the sort key.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Create a global secondary index (GSI) with subject_name as the partition key and student_id as the sort key.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 364,
    "question": "A developer wrote an application that uses an AWS Lambda function to asynchronously generate short videos based on requests from customers. This video generation can take up to 10 minutes. After the video is generated, a URL to download the video is pushed to the customer's web browser. The customer should be able to access these videos for at least 3 hours after generation.<br><br>Which solution will meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Store the video in the /tmp folder within the Lambda execution environment. Push a Lambda function URL to the customer.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Store the video in an Amazon Elastic File System (Amazon EFS) file system attached to the function. Generate a pre-signed URL for the video object and push the URL to the customer.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Store the video in Amazon S3. Generate a pre-signed URL for the video object and push the URL to the customer.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Store the video in an Amazon CloudFront distribution. Generate a pre-signed URL for the video object and push the URL to the customer.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 365,
    "question": "A developer is creating an AWS Lambda function that is invoked by messages to an Amazon Simple Notification Service (Amazon SNS) topic. The messages represent customer data updates from a customer relationship management (CRM) system<br><br>The developer wants the Lambda function to process only the messages that pertain to email address changes. Additional subscribers to the SNS topic will process any other messages.<br><br>Which solution will meet these requirements in the LEAST development effort?",
    "answers": [
      {
        "id": 1,
        "answer": "Use Lambda event filtering to allow only messages that are related to email address changes to invoke the Lambda function.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Use an SNS filter policy on the Lambda function subscription to allow only messages that are related to email address changes to invoke the Lambda function.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Subscribe an Amazon Simple Queue Service (Amazon SQS) queue to the SNS topic. Configure the SQS queue with a filter policy to allow only messages that are related to email address changes.<br>Connect the SQS queue to the Lambda function.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Configure the Lambda code to check the received message. If the message is not related to an email address change, configure the Lambda function to publish the message back to the SNS topic for the other subscribers to process.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 366,
    "question": "A developer is designing a fault-tolerant environment where client sessions will be saved.<br><br>How can the developer ensure that no sessions are lost if an Amazon EC2 instance fails?",
    "answers": [
      {
        "id": 1,
        "answer": "Use sticky sessions with an Elastic Load Balancer target group.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Use Amazon SQS to save session data.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Use Amazon DynamoDB to perform scalable session handling.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Use Elastic Load Balancer connection draining to stop sending requests to failing instances.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 367,
    "question": "A developer is creating AWS CloudFormation templates to manage an application's deployment in Amazon Elastic Container Service (Amazon ECS) through AWS CodeDeploy. The developer wants to automatically deploy new versions of the application to a percentage of users before the new version becomes available for all users.<br><br>How should the developer manage the deployment of the new version?",
    "answers": [
      {
        "id": 1,
        "answer": "Modify the CloudFormation template to include a Transform section and the AWS::CodeDeploy::BlueGreen hook.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Deploy the new version in a new CloudFormation stack. After testing is complete, update the application's DNS records for the new stack.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Run CloudFormation stack updates on the application stack to deploy new application versions when they are available.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Create a nested stack for the new version. Include a Transform section and the AWS::CodeDeploy::BlueGreen hook.",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 368,
    "question": "A developer has written a distributed application that uses microservices. The microservices are running on Amazon EC2 instances. Because of message volume, the developer is unable to match log output from each microservice to a specific transaction. The developer needs to analyze the message flow to debug the application.<br><br>Which combination of steps should the developer take to meet this requirement? (Choose two.)",
    "answers": [
      {
        "id": 1,
        "answer": "Download the AWS X-Ray daemon. Install the daemon on an EC2 instance. Ensure that the EC2 instance allows UDP traffic on port 2000.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Configure an interface VPC endpoint to allow traffic to reach the global AWS X-Ray daemon on TCP port 2000.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Enable AWS X-Ray. Configure Amazon CloudWatch to push logs to X-Ray.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Add the AWS X-Ray software development kit (SDK) to the microservices. Use X-Ray to trace requests that each microservice makes.",
        "correct": true
      },
      {
        "id": 5,
        "answer": "Set up Amazon CloudWatch metric streams to collect streaming data from the microservices.",
        "correct": false
      }
    ],
    "corrects": [
      1,
      4
    ],
    "multiple": true,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 369,
    "question": "A company is working on a new serverless application. A developer needs to find an automated way to deploy AWS Lambda functions and the dependent infrastructure with minimum coding effort. The application also needs to be reliable.<br><br>Which method will meet these requirements with the LEAST operational overhead?",
    "answers": [
      {
        "id": 1,
        "answer": "Build the application by using shell scripts to create .zip files for each Lambda function. Manually upload the .zip files to the AWS Management Console.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Build the application by using the AWS Serverless Application Model (AWS SAM). Use a continuous integration and continuous delivery (CI/CD) pipeline and the SAM CLI to deploy the Lambda functions.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Build the application by using shell scripts to create .zip files for each Lambda function. Upload the .zip files. Deploy the .zip files as Lambda functions by using the AWS CLI in a continuous integration and continuous delivery (CI/CD) pipeline.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Build a container for each Lambda function. Store the container images in AWS CodeArtifact. Deploy the containers as Lambda functions by using the AWS CLI in a continuous integration and continuous delivery (CI/CD) pipeline.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 370,
    "question": "A developer needs to modify an application architecture to meet new functional requirements. Application data is stored in Amazon DynamoDB and processed for analysis in a nightly batch. The system analysts do not want to wait until the next day to view the processed data and have asked to have it available in near-real time.<br><br>Which application architecture pattern would enable the data to be processed as it is received?",
    "answers": [
      {
        "id": 1,
        "answer": "Event driven",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Client-server driven",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Fan-out driven",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Schedule driven",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 371,
    "question": "A company hosts its application in the us-west-1 Region. The company wants to add redundancy in the us-east-1 Region.<br><br>The application secrets are stored in AWS Secrets Manager in us-west-1. A developer needs to replicate the secrets to us-east-1.<br><br>Which solution will meet this requirement?",
    "answers": [
      {
        "id": 1,
        "answer": "Configure secret replication for each secret. Add us-east-1 as a replication Region. Choose an AWS Key Management Service (AWS KMS) key in us-east-1 to encrypt the replicated secrets.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Create a new secret in us-east-1 for each secret. Configure secret replication in us-east-1. Set the source to be the corresponding secret in us-west-1. Choose an AWS Key Management Service (AWS KMS) key in us-west-1 to encrypt the replicated secrets.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Create a replication rule for each secret. Set us-east-1 as the destination Region. Configure the rule to run during secret rotation. Choose an AWS Key Management Service (AWS KMS) key in us-east-1 to encrypt the replicated secrets.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Create a Secrets Manager lifecycle rule to replicate each secret to a new Amazon S3 bucket in us-west-1. Configure an S3 replication rule to replicate the secrets to us-east-1.",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 372,
    "question": "A company runs an ecommerce application on AWS. The application stores data in an Amazon Aurora database.<br><br>A developer is adding a caching layer to the application. The caching strategy must ensure that the application always uses the most recent value for each data item.<br><br>Which caching strategy will meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Implement a TTL strategy for every item that is saved in the cache.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Implement a write-through strategy for every item that is created and updated.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Implement a lazy loading strategy for every item that is loaded.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Implement a read-through strategy for every item that is loaded.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 373,
    "question": "A company has a serverless application that uses Amazon API Gateway backed by AWS Lambda proxy integration. The company is developing several backend APIs. The company needs a landing page to provide an overview of navigation to the APIs.<br><br>A developer creates a new/LandingPage resource and a new GET method that uses mock integration.<br><br>What should the developer do next to meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Configure the integration request mapping template with Content-Type of text/html and statusCode of 200. Configure the integration response mapping template with Content-Type of application/json. In the integration response mapping template, include the LandingPage HTML code that references the APIs.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Configure the integration request mapping template with Content-Type of application/json. In the integration request mapping template, include the LandingPage HMTL code that references the APIs. Configure the integration response mapping template with Content-Type of text/html and statusCode of 200.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Configure the integration request mapping template with Content-Type of application/json and statusCode of 200. Configure the integration response mapping template with Content-Type of text/html. In the integration response mapping template, include the LandingPage HTML code that references the APIs.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Configure the integration request mapping template with Content-Type of text/html. In the integration request mapping template, include the LandingPage HTML code that references the APIs. Configure the integration response mapping template with Content-Type of application/json and statusCode of 200.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 374,
    "question": "A developer creates an AWS Lambda function that is written in Java. During testing, the Lambda function does not work how the developer expected. The developer wants to use tracing capabilities to troubleshoot the problem.<br><br>Which AWS service should the developer use to accomplish this goal?",
    "answers": [
      {
        "id": 1,
        "answer": "AWS Trusted Advisor",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Amazon CloudWatch",
        "correct": false
      },
      {
        "id": 3,
        "answer": "AWS X-Ray",
        "correct": true
      },
      {
        "id": 4,
        "answer": "AWS CloudTrail",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 375,
    "question": "A company is developing an application that will be accessed through the Amazon API Gateway REST API. Registered users should be the only ones who can access certain resources of this API. The token being used should expire automatically and needs to be refreshed periodically.<br><br>How can a developer meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Create an Amazon Cognito identity pool, configure the Amazon Cognito Authorizer in API Gateway, and use the temporary credentials generated by the identity pool.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Create and maintain a database record for each user with a corresponding token and use an AWS Lambda authorizer in API Gateway.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Create an Amazon Cognito user pool, configure the Cognito Authorizer in API Gateway, and use the identity or access token.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Create an IAM user for each API user, attach an invoke permissions policy to the API, and use an IAM authorizer in API Gateway.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 376,
    "question": "A company used AWS to develop an application for customers. The application includes an Amazon API Gateway API that invokes AWS Lambda functions. The Lambda functions process data and store the data in Amazon DynamoDB tables.<br><br>The company must monitor the entire application to identify potential bottlenecks in the architecture that can negatively affect customers.<br><br>Which solution will meet this requirement with the LEAST development effort?",
    "answers": [
      {
        "id": 1,
        "answer": "Instrument the application with AWS X-Ray. Inspect the service map to identify errors and issues.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Configure Lambda exceptions and additional logging to Amazon CloudWatch. Use CloudWatch Logs Insights to query the logs.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Configure API Gateway to log responses to Amazon CloudWatch. Create a metric filter for the TooManyRequestsException error message.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Use Amazon CloudWatch metrics for the DynamoDB tables to identify all the ProvisionedThroughputExceededException error messages.",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 377,
    "question": "A company launched an online portal to announce a new product that the company will release in 6 months. The portal requests that users enter an email address to receive communications about the product. The company needs to create a REST API that will store the email addresses in Amazon DynamoDB.<br><br>A developer has created an AWS Lambda function that can store the email addresses. The developer will deploy the Lambda function by using the AWS Serverless Application Model (AWS SAM). The developer must provide access to the Lambda function over HTTP.<br><br>Which solutions will meet these requirements with the LEAST additional configuration? (Choose two.)",
    "answers": [
      {
        "id": 1,
        "answer": "Expose the Lambda function by using function URLs.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Expose the Lambda function by using a Gateway Load Balancer.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Expose the Lambda function by using a Network Load Balancer.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Expose the Lambda function by using AWS Global Accelerator.",
        "correct": false
      },
      {
        "id": 5,
        "answer": "Expose the Lambda function by using Amazon API Gateway.",
        "correct": true
      }
    ],
    "corrects": [
      1,
      5
    ],
    "multiple": true,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 378,
    "question": "A company has a website that displays a daily newsletter. When a user visits the website, an AWS Lambda function processes the browser's request and queries the company's on-premises database to obtain the current newsletter. The newsletters are stored in English. The Lambda function uses the Amazon Translate TranslateText API operation to translate the newsletters, and the translation is displayed to the user.<br><br>Due to an increase in popularity, the website's response time has slowed. The database is overloaded. The company cannot change the database and needs a solution that improves the response time of the Lambda function.<br><br>Which solution meets these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Change to asynchronous Lambda function invocation.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Cache the translated newsletters in the Lambda/tmp directory.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Enable TranslateText API caching.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Change the Lambda function to use parallel processing.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 379,
    "question": "A developer is monitoring an application that runs on an Amazon EC2 instance. The developer has configured a custom Amazon CloudWatch metric with data granularity of 1 second. If any issues occur, the developer wants to be notified within 30 seconds by Amazon Simple Notification Service (Amazon SNS).<br><br>What should the developer do to meet this requirement?",
    "answers": [
      {
        "id": 1,
        "answer": "Configure a high-resolution CloudWatch alarm.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Set up a custom CloudWatch dashboard.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Use Amazon CloudWatch Logs Insights.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Change to a default CloudWatch metric.",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 380,
    "question": "A company has a web application that contains an Amazon API Gateway REST API. A developer has created an AWS CloudFormation template for the initial deployment of the application. The developer has deployed the application successfully as part of an AWS CodePipeline continuous integration and continuous delivery (CI/CD) process. All resources and methods are available through the deployed stage endpoint.<br><br>The CloudFormation template contains the following resource types:<br><br>•AWS::ApiGateway::RestApi<br>•AWS::ApiGateway::Resource<br>•AWS::ApiGateway::Method<br>•AWS::ApiGateway::Stage<br>•AWS::ApiGateway::Deployment<br><br>The developer adds a new resource to the REST API with additional methods and redeploys the template. CloudFormation reports that the deployment is successful and that the stack is in the UPDATE_COMPLETE state. However, calls to all new methods are returning 404 (Not Found) errors.<br><br>What should the developer do to make the new methods available?",
    "answers": [
      {
        "id": 1,
        "answer": "Specify the disable-rollback option during the update-stack operation.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Unset the CloudFormation stack failure options.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Add an AWS CodeBuild stage to CodePipeline to run the aws apigateway create-deployment AWS CLI command.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Add an action to CodePipeline to run the aws cloudfront create-invalidation AWS CLI command.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 381,
    "question": "A developer updates an AWS Lambda function that an Amazon API Gateway API uses. The API is the backend for a web application.<br><br>The developer needs to test the updated Lambda function before deploying the Lambda function to production. The testing must not affect any production users of the web application.<br><br>Which solution will meet these requirements in the MOST operationally efficient way?",
    "answers": [
      {
        "id": 1,
        "answer": "Create a canary release deployment for the existing API stage. Deploy the API to the existing stage. Test the updated Lambda function by using the existing URL.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Update the API Gateway API endpoint type to private. Deploy the changes to the existing API stage. Test the API by using the existing URL.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Create a new test API stage in API Gateway. Add stage variables to deploy the updated Lambda function to only the test stage. Test the updated Lambda function by using the new stage URL.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Create a new AWS CloudFormation stack to deploy a copy of the entire production API and Lambda function. Use the stack's API URL to test the updated Lambda function.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 382,
    "question": "A developer wants the ability to roll back to a previous version of an AWS Lambda function in the event of errors caused by a new deployment.<br><br>How can the developer achieve this with MINIMAL impact on users?",
    "answers": [
      {
        "id": 1,
        "answer": "Change the application to use an alias that points to the current version. Deploy the new version of the code. Update the alias to use the newly deployed version. If too many errors are encountered, point the alias back to the previous version.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Change the application to use an alias that points to the current version. Deploy the new version of the code. Update the alias to direct 10% of users to the newly deployed version. If too many errors are encountered, send 100% of traffic to the previous version.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Do not make any changes to the application. Deploy the new version of the code. If too many errors are encountered, point the application back to the previous version using the version number in the Amazon Resource Name (ARN).",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Create three aliases: new, existing, and router. Point the existing alias to the current version. Have the router alias direct 100% of users to the existing alias. Update the application to use the router alias. Deploy the new version of the code. Point the new alias to this version. Update the router alias to direct 10% of users to the new alias. If too many errors are encountered, send 100% of traffic to the existing alias.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 383,
    "question": "A company maintains a REST service using Amazon API Gateway and the API Gateway native API key validation. The company recently launched a new registration page, which allows users to sign up for the service. The registration page creates a new API key using CreateApiKey and sends the new key to the user. When the user attempts to call the API using this key, the user receives a 403 Forbidden error. Existing users are unaffected and can still call the API.<br><br>What code updates will grant these new users access to the API?",
    "answers": [
      {
        "id": 1,
        "answer": "The createDeployment method must be called so the API can be redeployed to include the newly created API key.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "The updateAuthorizer method must be called to update the API's authorizer to include the newly created API key.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "The importApiKeys method must be called to import all newly created API keys into the current stage of the API.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "The createUsagePlanKey method must be called to associate the newly created API key with the correct usage plan.",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 384,
    "question": "A company uses an AWS CloudFormation template to deploy and manage its AWS infrastructure. The CloudFormation template creates Amazon VPC security groups and Amazon EC2 security groups.<br><br>A manager finds out that some engineers modified the security groups of a few EC2 instances for testing purposes. A developer needs to determine what modifications occurred.<br><br>Which solution will meet this requirement?",
    "answers": [
      {
        "id": 1,
        "answer": "Add a Conditions section statement in the source YAML file of the template. Run the CloudFormation stack.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Perform a drift detection operation on the CloudFormation stack.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Execute a change set for the CloudFormation stack.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Use Amazon Detective to detect the modifications.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 385,
    "question": "An IAM role is attached to an Amazon EC2 instance that explicitly denies access to all Amazon S3 API actions. The EC2 instance credentials file specifies the IAM access key and secret access key, which allow full administrative access.<br><br>Given that multiple modes of IAM access are present for this EC2 instance, which of the following is correct?",
    "answers": [
      {
        "id": 1,
        "answer": "The EC2 instance will only be able to list the S3 buckets.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "The EC2 instance will only be able to list the contents of one S3 bucket at a time.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "The EC2 instance will be able to perform all actions on any S3 bucket.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "The EC2 instance will not be able to perform any S3 action on any S3 bucket.",
        "correct": true
      }
    ],
    "corrects": [
      4
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 386,
    "question": "A company uses an AWS Lambda function to transfer files from an Amazon S3 bucket to the company's SFTP server. The Lambda function connects to the SFTP server by using credentials such as username and password. The company uses Lambda environment variables to store these credentials.<br><br>A developer needs to implement encrypted username and password credentials.<br><br>Which solution will meet these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Remove the user credentials from the Lambda environment. Implement IAM database authentication.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Move the user credentials from Lambda environment variables to AWS Systems Manager Parameter Store.",
        "correct": true
      },
      {
        "id": 3,
        "answer": "Move the user credentials from Lambda environment variables to AWS Key Management Service (AWS KMS).",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Move the user credentials from the Lambda environment to an encrypted .txt file. Store the file in an S3 bucket.",
        "correct": false
      }
    ],
    "corrects": [
      2
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 387,
    "question": "A developer is creating a new batch application that will run on an Amazon EC2 instance. The application requires read access to an Amazon S3 bucket. The developer needs to follow security best practices to grant S3 read access to the application.<br><br>Which solution meets these requirements?",
    "answers": [
      {
        "id": 1,
        "answer": "Add the permissions to an IAM policy. Attach the policy to a role. Attach the role to the EC2 instance profile.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Add the permissions inline to an IAM group. Attach the group to the EC2 instance profile.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Add the permissions to an IAM policy. Attach the policy to a user. Attach the user to the EC2 instance profile.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "Add the permissions to an IAM policy. Use IAM web identity federation to access the S3 bucket with the policy.",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 388,
    "question": "A company has an application that receives batches of orders from partners every day. The application uses an AWS Lambda function to process the batches.<br><br>If a batch contains no orders, the Lambda function must publish to an Amazon Simple Notification Service (Amazon SNS) topic as soon as possible.<br><br>Which combination of steps will meet this requirement with the LEAST implementation effort? (Choose two.)",
    "answers": [
      {
        "id": 1,
        "answer": "Update the existing Lambda function's code to send an Amazon CloudWatch custom metric for the number of orders in a batch for each partner.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "Create a new Lambda function as an Amazon Kinesis data stream consumer. Configure the new Lambda function to track orders and to publish to the SNS topic when a batch contains no orders.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Set up an Amazon CloudWatch alarm that will send a notification to the SNS topic when the value of the custom metric is 0.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Schedule a new Lambda function to analyze Amazon CloudWatch metrics every 24 hours to identify batches that contain no orders. Configure the Lambda function to publish to the SNS topic.",
        "correct": false
      },
      {
        "id": 5,
        "answer": "Modify the existing Lambda function to log orders to an Amazon Kinesis data stream.",
        "correct": false
      }
    ],
    "corrects": [
      1,
      3
    ],
    "multiple": true,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 389,
    "question": "A developer has an application that uses an Amazon DynamoDB table with a configured local secondary index (LSI). During application testing, the DynamoDB table metrics report a ProvisionedThroughputExceededException error message. The number of requests made by the test suite did not exceed the table's provisioned capacity limits.<br><br>What is the cause of this issue?",
    "answers": [
      {
        "id": 1,
        "answer": "The data in the table's partition key column is not evenly distributed.",
        "correct": true
      },
      {
        "id": 2,
        "answer": "The LSI's capacity is different from the table's capacity.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "The application is not implementing exponential backoff retry logic while interacting with the DynamoDB API.",
        "correct": false
      },
      {
        "id": 4,
        "answer": "The application has the IAM permission to query the DynamoDB table but not to query the LSI.",
        "correct": false
      }
    ],
    "corrects": [
      1
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  },
  {
    "id": 390,
    "question": "A developer manages a website that distributes its content by using Amazon CloudFront. The website's static artifacts are stored in an Amazon S3 bucket.<br><br>The developer deploys some changes and can see the new artifacts in the S3 bucket. However, the changes do not appear on the webpage that the CloudFront distribution delivers.<br><br>How should the developer resolve this issue?",
    "answers": [
      {
        "id": 1,
        "answer": "Configure S3 Object Lock to update to the latest version of the files every time an S3 object is updated.",
        "correct": false
      },
      {
        "id": 2,
        "answer": "Configure the S3 bucket to clear all old objects from the bucket before new artifacts are uploaded.",
        "correct": false
      },
      {
        "id": 3,
        "answer": "Set CloudFront to invalidate the cache after the artifacts have been deployed to Amazon S3.",
        "correct": true
      },
      {
        "id": 4,
        "answer": "Set CloudFront to modify the distribution origin after the artifacts have been deployed to Amazon S3.",
        "correct": false
      }
    ],
    "corrects": [
      3
    ],
    "multiple": false,
    "domain": "",
    "correctAnswerExplanations": [],
    "incorrectAnswerExplanations": [],
    "references": []
  }
]